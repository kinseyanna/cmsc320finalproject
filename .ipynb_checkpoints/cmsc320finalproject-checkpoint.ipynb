{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC320 Final Project\n",
    "## Kinsey Smith, Sarah Bullard, Yiwen Shen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our project is surrounding the Twitter account of the United States' current president, Donald Trump (@realDonaldTrump). We focused on the sentiment of the tweets of this account versus each individual tweet's replies. Our intention was to find out the difference between the sentiment of the tweet and the sentiment of its replies, and how it would reflect our current political climate. <b>Our hypothesis was that Donald Trump's account would have more negative replies to his positive tweets, since the current political climate (especially on December 9th, 2017, the date that we chose to analyze his tweets) does not favor Donald Trump.</b>\n",
    "\n",
    "<img src=\"trump_twitter_image.jpg\">\n",
    "\n",
    "Sentiment analysis is a way of classifying a text as having a positive, negative, or neutral sentiment using text analysis. Just using sentiment analysis should be enough for us to classify the tweets as positive, negative, or neutral. However, <b>sentiment analysis has not been able to fully detect things such as sarcasm and satire</b>, and Trump's replies are full of people who are using sarcasm and satire. He has even been called the \"Most Trolled Person On the Internet\" by a news outlet (https://www.scoopwhoop.com/Heres-Why-Donald-Trump-Is-The-Most-Trolled-Person-On-The-Internet-These-Days/). Therefore, we had to think of other features to incorporate in order to truly analyze the sentimentality of each tweet.\n",
    "\n",
    "Side note: <b>We did not use these extra feature vectors on Trump's tweets</b>, since there was a very low probability that Trump was being sarcastic in his tweets, as when he is being \"sarcastic\", he is actually just making a negative comment about a person or organization and says it is misinterpreted (http://abcnews.go.com/Politics/times-donald-trump-sarcastic-misinterpreted/story?id=41328374). Instead, we used these feature vectors on Trump's followers and the sample of replies we collected from them. \n",
    "\n",
    "\n",
    "<b> The features in our feature vector are as follows: </b>\n",
    "\n",
    "Our first feature was the original sentiment analysis, because although it is not reliably conclusive on its own, it can give us a basis about the mood of the sentence. \n",
    "\n",
    "The second feature we worked on focused on the user who posted the reply to the specific tweet. We checked whether or not the user was following other accounts that aligned with Donald Trump's or BLM's views, including politicians of either party.\n",
    "\n",
    "The third feature we worked on also focused on the user who posted the reply to the specific tweet. We compared the user's hashtags for the last year to known Trump-positive and BLM-positive hashtags, and noted numerically the number of hashtags that were similar for each user. \n",
    "\n",
    "\n",
    "After we collected the features, we used the <b> name of classifier </b> to classify the data. Since the dataset we used was small (for reasons that will be explained further in this notebook), we created the training dataset ourselves and compared that to the real dataset using that classifier. \n",
    "\n",
    "This notebook will be organized into four parts: Data Extraction, Data Manipulation, Data Analysis, and Data Visualization. Each part will show how we manipulated the Twitter's API in order to get the tweets that we need and come to the conclusion that we have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# All of the imports that we need for the project.\n",
    "import tweepy\n",
    "from tweepy import Cursor\n",
    "import textblob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import unicodecsv\n",
    "from unidecode import unidecode\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Twitter's Data\n",
    "\n",
    "In order to access Twitter's API, we had to create applications and personally get authentication tokens. Even though anyone that has a Twitter account is allowed access to Twitter's data as long as they fill out an Application form, we cannot give out these confidential tokens on this public notebook becuase it is a privacy risk. In order to get past this hurdle, we created a function that would pull from our own files on our own machines for these tokens. In the cell below is a copy of credentials.py, without the confidential information. See below the code we used to access Twitter's API in order to get the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of credentials.py \n",
    "* Comment on file - This is a file that holds confidential information about a Twitter user and their authentication tokens. Please do not read further if you are not authorized.\n",
    "  \n",
    "CONSUMER_KEY = ' '\n",
    "\n",
    "CONSUMER_SECRET = ' '\n",
    "\n",
    "ACCESS_TOKEN = ' '\n",
    "\n",
    "ACCESS_SECRET = ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from credentials import *\n",
    "#A function that takes these credentials and sets up the API.\n",
    "def api_setup():\n",
    "    #application authentication allows more data retrival \n",
    "    auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    return api\n",
    "# Extracting the tweets\n",
    "extract_tweets = api_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Donald Trump Replies\n",
    "tweet_ids_donald = []\n",
    "for page in tweepy.Cursor(extract_tweets.user_timeline,screen_name=\"realDonaldTrump\").pages(20):\n",
    "    for item in page:\n",
    "        tweet_ids_donald.append(item.id_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = tweepy.Cursor(extract_tweets.search,q=\"to:realDonaldTrump\").items(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query2 = tweepy.Cursor(extract_tweets.search,q=\"to:Blklivesmatter\").items(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in query:\n",
    "    if replies_donald.get(tweet.in_reply_to_status_id_str) != None:\n",
    "        #add it to the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in query2:\n",
    "    if replies_blm.get(tweet.in_reply_to_status_id_str) != None:\n",
    "        #add it to the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the data to their individual CSVs\n",
    "\n",
    "Once we accessed the data from Twitter's API, we started querying. However, since Twitter has a rule of a maximum of 15 queries in 15 minutes, and we were querying for replies of more than 15 tweets, we had to find another way to access the data when working with it. Since Donald Trump also tweets really often each day, and we were only able to slowly get the data, we decided to analyze the data from his tweets on December 9th, 2017, and their replies. December 9th was the date we chose because Trump had tweeted a mix of controversial and non-controversial tweets that day, and then we could see whether or not the sentimentality of the replies for each tweet was being affected by the controversiality of each tweet itself. Their replies were not dated, but we chose them randomly from the total replies to each tweet. We added the tweets of that day and their replies to individual CSVs to work with them. We slowly added them to these CSVs to circumvent the 15-queries-maximum rule.\n",
    "\n",
    "<b> Getting Donald Trump Tweets. </b>\n",
    "\n",
    "The piece of code below that is referenced from nicolewhite will find all trump's tweets for a year and add it to a csv called trump_tweets.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/nicolewhite/167828e51d8f2b6fad75\n",
    "users = [\"realDonaldTrump\"]\n",
    "with open('trump_tweets.csv', 'wb') as file:\n",
    "    writer = unicodecsv.writer(file, delimiter = ',', quotechar = '\"')\n",
    "    # Write header row.\n",
    "    writer.writerow([\"name\",\n",
    "                    \"username\",\n",
    "                    \"followers_count\",\n",
    "                    \"listed_count\",\n",
    "                    \"following\",\n",
    "                    \"favorites\",\n",
    "                    \"verified\",\n",
    "                    \"default_profile\",\n",
    "                    \"location\",\n",
    "                    \"time_zone\",\n",
    "                    \"statuses_count\",\n",
    "                    \"description\",\n",
    "                    \"geo_enabled\",\n",
    "                    \"contributors_enabled\",\n",
    "                    \"tweet_id\",\n",
    "                    \"tweet_time\",\n",
    "                    \"tweet_text\",\n",
    "                    \"tweet_lat\",\n",
    "                    \"tweet_long\",\n",
    "                    \"tweet_source\",\n",
    "                    \"tweet_in_reply_to_screen_name\",\n",
    "                    \"tweet_direct_reply\",\n",
    "                    \"tweet_retweet_status\",\n",
    "                    \"tweet_retweet_count\",\n",
    "                    \"tweet_favorite_count\",\n",
    "                    \"tweet_hashtags\",\n",
    "                    \"tweet_hashtags_count\",\n",
    "                    \"tweet_urls\",\n",
    "                    \"tweet_urls_count\",\n",
    "                    \"tweet_user_mentions\",\n",
    "                    \"tweet_user_mentions_count\",\n",
    "                    \"tweet_media_type\",\n",
    "                    \"tweet_contributors\"])\n",
    "\n",
    "    for user in users:\n",
    "        user_obj = api.get_user(user)\n",
    "\n",
    "        # Gather info specific to the current user.\n",
    "        user_info = [user_obj.name,\n",
    "                     user_obj.screen_name,\n",
    "                     user_obj.followers_count,\n",
    "                     user_obj.listed_count,\n",
    "                     user_obj.friends_count,\n",
    "                     user_obj.favourites_count,\n",
    "                     user_obj.verified,\n",
    "                     user_obj.default_profile,\n",
    "                     user_obj.location,\n",
    "                     user_obj.time_zone,\n",
    "                     user_obj.statuses_count,\n",
    "                     user_obj.description,\n",
    "                     user_obj.geo_enabled,\n",
    "                     user_obj.contributors_enabled]\n",
    "\n",
    "        # Get 5000 most recent tweets for the current user.\n",
    "        # api.search, q=\"to:\"+user  api.user_timeline, screen_name = user \n",
    "\n",
    "        \n",
    "        for tweet in Cursor(api.user_timeline, screen_name = user).items(5000):\n",
    "\n",
    "            # Latitude and longitude stored as array of floats within a dictionary.\n",
    "            lat = tweet.coordinates['coordinates'][1] if tweet.coordinates != None else None\n",
    "            long = tweet.coordinates['coordinates'][0] if tweet.coordinates != None else None\n",
    "            # If tweet is not in reply to a screen name, it is not a direct reply.\n",
    "            direct_reply = True if tweet.in_reply_to_screen_name != \"\" else False\n",
    "            # Retweets start with \"RT ...\"\n",
    "            retweet_status = True if tweet.text[0:3] == \"RT \" else False\n",
    "\n",
    "            # Get info specific to the current tweet of the current user.\n",
    "            tweet_info = [tweet.id,\n",
    "                          tweet.created_at,\n",
    "                          unidecode(tweet.text),\n",
    "                          lat,\n",
    "                          long,\n",
    "                          tweet.source,\n",
    "                          tweet.in_reply_to_screen_name,\n",
    "                          direct_reply,\n",
    "                          retweet_status,\n",
    "                          tweet.retweet_count,\n",
    "                          tweet.favorite_count]\n",
    "\n",
    "            # Below entities are stored as variable-length dictionaries, if present.\n",
    "            hashtags = []\n",
    "            hashtags_data = tweet.entities.get('hashtags', None)\n",
    "            if(hashtags_data != None):\n",
    "                for i in range(len(hashtags_data)):\n",
    "                    hashtags.append(unidecode(hashtags_data[i]['text']))\n",
    "\n",
    "            urls = []\n",
    "            urls_data = tweet.entities.get('urls', None)\n",
    "            if(urls_data != None):\n",
    "                for i in range(len(urls_data)):\n",
    "                    urls.append(unidecode(urls_data[i]['url']))\n",
    "\n",
    "            user_mentions = []\n",
    "            user_mentions_data = tweet.entities.get('user_mentions', None)\n",
    "            if(user_mentions_data != None):\n",
    "                for i in range(len(user_mentions_data)):\n",
    "                    user_mentions.append(unidecode(user_mentions_data[i]['screen_name']))\n",
    "\n",
    "            media = []\n",
    "            media_data = tweet.entities.get('media', None)\n",
    "            if(media_data != None):\n",
    "                for i in range(len(media_data)):\n",
    "                    media.append(unidecode(media_data[i]['type']))\n",
    "\n",
    "            contributors = []\n",
    "            if(tweet.contributors != None):\n",
    "                for contributor in tweet.contributors:\n",
    "                    contributors.append(unidecode(contributor['screen_name']))\n",
    "\n",
    "            more_tweet_info = [', '.join(hashtags),\n",
    "                               len(hashtags),\n",
    "                               ', '.join(urls),\n",
    "                               len(urls),\n",
    "                               ', '.join(user_mentions),\n",
    "                               len(user_mentions),\n",
    "                               ', '.join(media),\n",
    "                               ', '.join(contributors)]\n",
    "\n",
    "            # Write data to CSV.\n",
    "            writer.writerow(user_info + tweet_info + more_tweet_info)\n",
    "\n",
    "        # Show progress.\n",
    "        print(\"Wrote tweets by %s to CSV.\" % user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Getting replies to Donald Trump Tweets. </b>\n",
    "\n",
    "The following code will collect replies to trump's tweet to a csv file. Due to twitter's rate limit on search api we only collect 20 replies. With the reply_id we will be able to see which Trump's tweet above the user is replying to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_id_list = data_donald['tweet_id'].tolist()\n",
    "\n",
    "with open('trump_replies.csv', 'wb') as file:\n",
    "    writer = unicodecsv.writer(file, delimiter = ',', quotechar = '\"')\n",
    "    writer.writerow([\n",
    "                    \"username\",\n",
    "                    \"id\",\n",
    "                    \"reply_id\",\n",
    "                    \"date\",\n",
    "                    \"tweet\"\n",
    "                    ])\n",
    "                     \n",
    "\n",
    "    for otweet_id in tweet_id_list:\n",
    "        \n",
    "        i=0\n",
    "        print(otweet_id)\n",
    "        for tweet in tweepy.Cursor(extractor.search, q=\"to:realDonaldTrump\", since_id= otweet_id).items():\n",
    "                \n",
    "                \n",
    "            if str(tweet.in_reply_to_status_id) == str(otweet_id):\n",
    "                i=i+1\n",
    "                print(i)\n",
    "                if(i==20):\n",
    "                    break\n",
    "\n",
    "                info = [tweet.user.screen_name,\n",
    "                         tweet.id,\n",
    "                         tweet.in_reply_to_status_id,\n",
    "                         tweet.created_at,\n",
    "                         unidecode(tweet.text),\n",
    "                        ]\n",
    "\n",
    "\n",
    "                writer.writerow(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the Data in a Functional Way\n",
    "\n",
    "Now that the data is in a csv and collected, we can put it into a dataframe to work with. \n",
    "\n",
    "We also deleted unnecessary columns in the tweet json, like followers_count and following, which don't matter in regards to what we are doing. Since the Twitter json structure doesn't include the tweet id itself and (if it is a reply) the id of the tweet it is replying to, we had to put that information as well as the text of the tweet (to match them) into a separate CSV and compare them to add both sets of information to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939680422493073408</td>\n",
       "      <td>2017-12-10 02:17:25</td>\n",
       "      <td>No American should be separated from their lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-09 23:47:55</td>\n",
       "      <td>Great Army - Navy Game. Army wins 14 to 13 and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939634404267380736</td>\n",
       "      <td>2017-12-09 23:14:34</td>\n",
       "      <td>.@daveweigel of the Washington Post just admit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939616077356642304</td>\n",
       "      <td>2017-12-09 22:01:44</td>\n",
       "      <td>.@DaveWeigel @WashingtonPost put out a phony p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939564681743814661</td>\n",
       "      <td>2017-12-09 18:37:31</td>\n",
       "      <td>Have a great game today, @USArmy and @USNavy -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username            tweet_id           tweet_time  \\\n",
       "0  realDonaldTrump  939680422493073408  2017-12-10 02:17:25   \n",
       "1  realDonaldTrump  939642796289470464  2017-12-09 23:47:55   \n",
       "2  realDonaldTrump  939634404267380736  2017-12-09 23:14:34   \n",
       "3  realDonaldTrump  939616077356642304  2017-12-09 22:01:44   \n",
       "4  realDonaldTrump  939564681743814661  2017-12-09 18:37:31   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  No American should be separated from their lov...  \n",
       "1  Great Army - Navy Game. Army wins 14 to 13 and...  \n",
       "2  .@daveweigel of the Washington Post just admit...  \n",
       "3  .@DaveWeigel @WashingtonPost put out a phony p...  \n",
       "4  Have a great game today, @USArmy and @USNavy -...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Donald Tweets\n",
    "data_donald = pd.read_csv(\"trump_tweets.csv\", dtype={'tweet_id':str})\n",
    "del data_donald[\"name\"]\n",
    "del data_donald[\"followers_count\"]\n",
    "del data_donald[\"listed_count\"]\n",
    "del data_donald[\"following\"]\n",
    "del data_donald[\"favorites\"]\n",
    "del data_donald[\"verified\"]\n",
    "del data_donald[\"default_profile\"]\n",
    "del data_donald[\"statuses_count\"]\n",
    "del data_donald[\"description\"]\n",
    "del data_donald[\"geo_enabled\"]\n",
    "del data_donald[\"contributors_enabled\"]\n",
    "del data_donald[\"tweet_lat\"]\n",
    "del data_donald[\"tweet_long\"]\n",
    "del data_donald[\"tweet_source\"]\n",
    "del data_donald[\"tweet_in_reply_to_screen_name\"]\n",
    "del data_donald[\"tweet_direct_reply\"]\n",
    "del data_donald[\"tweet_retweet_count\"]\n",
    "del data_donald[\"tweet_favorite_count\"]\n",
    "del data_donald[\"tweet_hashtags_count\"]\n",
    "del data_donald[\"tweet_urls\"]\n",
    "del data_donald[\"tweet_urls_count\"]\n",
    "del data_donald[\"tweet_retweet_status\"]\n",
    "del data_donald[\"tweet_hashtags\"]\n",
    "del data_donald[\"tweet_user_mentions\"]\n",
    "del data_donald[\"tweet_media_type\"]\n",
    "del data_donald[\"tweet_contributors\"]\n",
    "del data_donald[\"tweet_user_mentions_count\"]\n",
    "del data_donald[\"location\"]\n",
    "del data_donald[\"time_zone\"]\n",
    "data_donald.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the dataframe resulting from the trump_replies CSV. As we notice due to the constraint of the search api, the replies we got are all very recent as in 12-11 compared with the 12-9 in the original tweets. This is due to the search api searching from most recent and we have no comntrol of. This may affect the result as the recent tweets may be affected by recent events. This can be solbved by uisng a better search engine that dosen't have rate limit and can sample search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...  \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ  \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia  \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s  \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replies of Trump\n",
    "data_donald_replies = pd.read_csv(\"trump_replies.csv\", dtype={'reply_id':str})\n",
    "\n",
    "data_donald_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "As explained before, sentiment analysis is a basic way of analyzing a text to tell if it is of positive, negative, or neutral sentiment. NLTK is the library we will use to do this section. This will be one of the features for the feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "#Getting the sentiment analysis for each type of tweet\n",
    "neg_donald = []\n",
    "pos_donald = []\n",
    "neu_donald = []\n",
    "comp_donald = []\n",
    "neg_donald_replies = []\n",
    "pos_donald_replies = []\n",
    "neu_donald_replies = []\n",
    "comp_donald_replies = []\n",
    "for _,x in data_donald.iterrows():\n",
    "    neg_donald.append(sia.polarity_scores(x[\"tweet_text\"])[\"neg\"])\n",
    "    pos_donald.append(sia.polarity_scores(x[\"tweet_text\"])[\"pos\"])\n",
    "    neu_donald.append(sia.polarity_scores(x[\"tweet_text\"])[\"neu\"])\n",
    "    comp_donald.append(sia.polarity_scores(x[\"tweet_text\"])[\"compound\"])\n",
    "for _,x in data_donald_replies.iterrows():\n",
    "    neg_donald_replies.append(sia.polarity_scores(x[\"tweet\"])[\"neg\"])\n",
    "    pos_donald_replies.append(sia.polarity_scores(x[\"tweet\"])[\"pos\"])\n",
    "    neu_donald_replies.append(sia.polarity_scores(x[\"tweet\"])[\"neu\"])\n",
    "    comp_donald_replies.append(sia.polarity_scores(x[\"tweet\"])[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding the scores to the columns of the dataframe\n",
    "data_donald[\"neg_sentiment\"] = neg_donald\n",
    "data_donald[\"pos_sentiment\"] = pos_donald\n",
    "data_donald[\"neu_sentiment\"] = neu_donald\n",
    "data_donald[\"comp_sentiment\"] = comp_donald\n",
    "data_donald_replies[\"neg_sentiment\"] = neg_donald_replies\n",
    "data_donald_replies[\"pos_sentiment\"] = pos_donald_replies\n",
    "data_donald_replies[\"neu_sentiment\"] = neu_donald_replies\n",
    "data_donald_replies[\"comp_sentiment\"] = comp_donald_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>comp_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939680422493073408</td>\n",
       "      <td>2017-12-10 02:17:25</td>\n",
       "      <td>No American should be separated from their lov...</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-09 23:47:55</td>\n",
       "      <td>Great Army - Navy Game. Army wins 14 to 13 and...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939634404267380736</td>\n",
       "      <td>2017-12-09 23:14:34</td>\n",
       "      <td>.@daveweigel of the Washington Post just admit...</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.6046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939616077356642304</td>\n",
       "      <td>2017-12-09 22:01:44</td>\n",
       "      <td>.@DaveWeigel @WashingtonPost put out a phony p...</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.904</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>939564681743814661</td>\n",
       "      <td>2017-12-09 18:37:31</td>\n",
       "      <td>Have a great game today, @USArmy and @USNavy -...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username            tweet_id           tweet_time  \\\n",
       "0  realDonaldTrump  939680422493073408  2017-12-10 02:17:25   \n",
       "1  realDonaldTrump  939642796289470464  2017-12-09 23:47:55   \n",
       "2  realDonaldTrump  939634404267380736  2017-12-09 23:14:34   \n",
       "3  realDonaldTrump  939616077356642304  2017-12-09 22:01:44   \n",
       "4  realDonaldTrump  939564681743814661  2017-12-09 18:37:31   \n",
       "\n",
       "                                          tweet_text  neg_sentiment  \\\n",
       "0  No American should be separated from their lov...          0.213   \n",
       "1  Great Army - Navy Game. Army wins 14 to 13 and...          0.000   \n",
       "2  .@daveweigel of the Washington Post just admit...          0.235   \n",
       "3  .@DaveWeigel @WashingtonPost put out a phony p...          0.096   \n",
       "4  Have a great game today, @USArmy and @USNavy -...          0.000   \n",
       "\n",
       "   pos_sentiment  neu_sentiment  comp_sentiment  \n",
       "0          0.225          0.562          0.0772  \n",
       "1          0.486          0.514          0.9229  \n",
       "2          0.062          0.704         -0.6046  \n",
       "3          0.000          0.904         -0.2023  \n",
       "4          0.304          0.696          0.8519  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_donald.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>comp_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \\\n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...   \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ   \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia   \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s   \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!   \n",
       "\n",
       "   neg_sentiment  pos_sentiment  neu_sentiment  comp_sentiment  \n",
       "0          0.536          0.119          0.345          -0.871  \n",
       "1          0.000          0.000          1.000           0.000  \n",
       "2          0.000          0.286          0.714           0.340  \n",
       "3          0.000          0.000          1.000           0.000  \n",
       "4          0.000          0.000          1.000           0.000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_donald_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Conclusion\n",
    "\n",
    "As you can see, most of the sentiment analysis done on the tweets is mainly neutral, when it should not be. For example, the tweet at index 2 starts off with \"go play roulette in Russia...\", which is obviously negative to humans, but to a machine, it is 71.4% neutral. Therefore, we're going to need other ways of telling whether or not a person is being negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following Feature Vector\n",
    "\n",
    "The following code will find who the users from data_donald_replies are following and will put that into a column called score. Starting at 0, if they’re following people that are known to be pro Donald Trump or generally Republican they are added 1 to their score, similarly if they are following people that are known to be against Donald Trump or generally Democratic they are subtracted one from their score. We created these lists of \"left\" and \"right\" follower handles from research into prominent pro- and con-Donald Trump Twitter users, and from our own experience of using Twitter. Again, due to api's rate limit this took very long time and we had to store the results in a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right_wing_handles_string = \",@AnnCoulter,@StefanMolyneux,@MarkSteynOnline,@ezralevant,@nntaleb,@Lauren_Southern,@RealJamesWoods,@IngrahamAngle,@benshapiro,@charliekirk11,@jihadwatchRS,@scrowder,@RubinReport,@Nigel_Farage,@michellemalkin,@PrisonPlanet,@ScottAdamsSays,@andrewklavan,@Gavin_McInnes,@Cernovich,@TuckerCarlson,@mitchellvii,@NolteNC,@JamesOKeefeIII,@DLoesch,@JackPosobiec,@BuckSexton,@KatiePavlich,@marklevinshow,@seanhannity,@guypbenson,@JimDeMint,@BrentBozell,@larryelder,@BillOReilly,@limbaugh,@foxnews,@foxtv\"\n",
    "right_wing_handles = right_wing_handles_string.split(\",@\")   \n",
    "left_wing_handles_string = \",@People4Bernie,@BuzzfeedBen,@jonlovett,@ChrisMurphyCT,@HeerJeet,@deray,@chrislhayes,@ezraklein,@jbouie,@cjane87,@julietlapidos,@meaganmday,@emmaogreen,@ObsoleteDogma,@billmaher,@BillNye,@iamjohnoliver,@kmcnuggets,@StephenAtHome,@donnabrazile,@PPact,@iraglass,@chelseahandler,@kamalaharris,@elizabethwarren,@sensherrodbrown,@kumailn,@jk_rowling,@cnni,@cnnbrk,@washingtonpost,@nytimes,@WSJ,@nbcsnl,@megynkelly,@huffpost,@huffpostwomen,@nbcnews,@ariannahuff,@comey,@MeghanMcCain,@chelseaclinton,@hillaryclinton\"\n",
    "left_wing_handles = left_wing_handles_string.split(\",@\")  \n",
    "\n",
    "right_wing_handles.pop(0)\n",
    "left_wing_handles.pop(0)\n",
    "\n",
    "#getting user's following list\n",
    "fl_dict = {}\n",
    "for u_name in username_list:\n",
    "    fl =[]\n",
    "    users = tweepy.Cursor(extractor.friends, screen_name=u_name, count = 200).items()\n",
    "    for u in users:\n",
    "        fl.append(u.screen_name)\n",
    "     \n",
    "    fl_dict[u_name] = fl\n",
    "    \n",
    "#for each user, find how many they are following that are in right wing handles and that for left wing as well\n",
    "#the score will be right minus left\n",
    "score_list=[]\n",
    "for user in fl_dict:\n",
    "        user_set = set(fl_dict[user])\n",
    "        score= len(list(user_set & right_wing_set)) - len(list( user_set & left_wing_set))\n",
    "\n",
    "\n",
    "#the data is then saved to csv called\n",
    "data_donald_replies['following'] = score_list\n",
    "#data_donald_replies.to_csv(\"trump_replies_with_following_feature.csv\", sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_donald_replies_with_following_feature = pd.read_csv(\"trump_replies_with_following_feature.csv\")\n",
    "data_donald_replies[\"following\"] = data_donald_replies_with_following_feature[\"following_feature_vector\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from the replies csv with following feature. As we can see from the first 5 replies to Trump, the following_feature_vector are mostly negative, meaning that they follow more anti-Trump Twitter users than pro-Trump ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>following</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \\\n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...   \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ   \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia   \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s   \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!   \n",
       "\n",
       "   following  \n",
       "0         -8  \n",
       "1         -7  \n",
       "2         -1  \n",
       "3         -3  \n",
       "4         -3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_donald_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note about Repeated Usernames\n",
    "\n",
    "Before proceeding to the hashtag feature vector, it's important to clarify that we do not actually have 250 unique users in the table of replies to President Trump's tweets. \n",
    "\n",
    "The code below shows this. First, we collect each entry in the username column of our replies table into a list. Then we iterate through that list and store the values into a dictionary mapping unique usernames to the number of times they appear in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of unique users is  195 .\n"
     ]
    }
   ],
   "source": [
    "user_list = []\n",
    "\n",
    "for _, x in data_donald_replies.iterrows():\n",
    "    user_list.append(x['username'])\n",
    "\n",
    "uniques = {}\n",
    "\n",
    "for u in user_list:\n",
    "    if not(u in uniques):\n",
    "        uniques[u] = 1\n",
    "    else:\n",
    "        old_val = uniques[u]\n",
    "        new_val = old_val + 1\n",
    "        uniques[u] = new_val\n",
    "\n",
    "print(\"The total number of unique users is \", len(uniques.keys()), \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hashtag Feature Vector\n",
    "\n",
    "The next feature vector that we want to add to our table is for the hashtags that a given user has used. We have compiled a list of hashtags that are popular among right-wing users, and another list of hashtags that are popular among left-wing users. \n",
    "\n",
    "We'll get the tweet history of each user, parse each tweet for hashtags, and then calculate a value for the user which will be that user's hashtag feature vector. 0 indicates neutrality in terms of hashtags. The more positive the value, the more right-wing the hashtags; the more negative the value, the more left-wing the hashtags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loading left- and right-wing hashtags </b>\n",
    "\n",
    "The next step is to load the left- and right-wing hashtags into lists, as well. We compiled popular hashtags of each party into separate files. The code below parses those files and puts the hashtags into lists so they can be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_hashtags = []\n",
    "right_hashtags = []\n",
    "\n",
    "with open(\"left_hashtags.rtf\") as f:\n",
    "    content = f.readlines()\n",
    "    left_hashtags = content[0].split(\",\")\n",
    "    \n",
    "\n",
    "for x in left_hashtags:\n",
    "    if (x.endswith(\"\\n\")):\n",
    "        new_x = x[:-1]\n",
    "        left_hashtags.remove(x)\n",
    "        left_hashtags.append(new_x)\n",
    "    \n",
    "with open(\"right_hashtags.rtf\") as f:\n",
    "    content = f.readlines()\n",
    "    right_hashtags = content[0].split(\",\")\n",
    "    \n",
    "for x in right_hashtags:\n",
    "    if (x.endswith(\"\\n\")):\n",
    "        new_x = x[:-1]\n",
    "        right_hashtags.remove(x)\n",
    "        right_hashtags.append(new_x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> A function to calculate a user's \"hashtag alignment\" </b>\n",
    "\n",
    "Now that we have the hashtags to look for in lists, it's time to find out what these hashtags say about their users.\n",
    "\n",
    "We already have tweet histories for each of the individual users stored in csv files. These tweet histories were obtained using [a script from the Github user yanofsky](https://gist.github.com/yanofsky/5436496). This script allows us to get up to 3240 tweets from the selected user's tweet history.\n",
    "\n",
    "The script uses tweepy, which unfortunately does impose limits on the results it gives. Tweepy will only allow us to access tweets posted within the past 1–2 weeks. Because we are trying to find out about the political alignment of a particular user, that is not ideal. However, it is important to consider that people can and do change over time. The hashtags we use to create this feature vector represent the user's political leanings near the time of their reply to President Trump's tweets.\n",
    "\n",
    "As described above, we only have 195 unique users whose tweet history we can gather. However, one user (SueMarvin3), has made her settings private so that we cannot access her tweet history. So we have a total of 194 unique users whose tweets we can gather. \n",
    "\n",
    "The function below works as follows: A given user's tweet history is read in from his or her file. Each tweet is split up into words, and words that start with the # character are appended to a list. The function then iterates through that list, adding 1 to an integer if the hashtag is \"right-wing\" or subtracting one if it is \"left-wing\". That \"alignment\" value is then returned.\n",
    "\n",
    "If the user uses a given hashtag more than once, that will factor into the score. This is because the more times a hashtag is used, the more passionate the user is presumed to be about that topic, and by extension, about that end of the political spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hashtag_alignment(username):\n",
    "    \n",
    "    # loading tweet history for the user\n",
    "    filename = \"user_tweets/\" + username + \"_tweets.csv\"\n",
    "    curr_db = pd.read_csv(filename)\n",
    "\n",
    "    # list to hold user's hashtags\n",
    "    hashtags = []\n",
    "\n",
    "    # iterating through tweet history\n",
    "    for _, x in curr_db.iterrows():\n",
    "        tweet = x['text']\n",
    "        \n",
    "        # splitting tweet into words\n",
    "        words = tweet.split(' ')\n",
    "        \n",
    "        # iterating through words to find hashtag\n",
    "        for w in words:\n",
    "            w = w[2:]\n",
    "            \n",
    "            # appending a hashtag to the list of this user's hashtags\n",
    "            if (w.startswith(\"#\")):\n",
    "                new_w = w[1:]\n",
    "                hashtags.append(new_w)\n",
    "            \n",
    "    alignment = 0\n",
    "\n",
    "    # iterating through the stored hashtags to calculate alignment\n",
    "    for x in hashtags:\n",
    "        if (x.lower() in right_hashtags):\n",
    "            alignment += 1\n",
    "        elif (x.lower() in left_hashtags):\n",
    "            alignment -= 1\n",
    "            \n",
    "    return alignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Iterating through users </b>\n",
    "\n",
    "Next, we iterate through the user list we made in an earlier step and calculate the alignment for each user. We append each alignment to a list so that we can add it as a feature vector column in our database later.\n",
    "\n",
    "We are using the original user list to do this, which includes all the repeat usernames. This will take a little bit longer, but it will result in a list of hashtag alignments that are in the correct order to be added directly as a column to our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting hashtag alignment for ZoltanCaptain ...done.\n",
      "Getting hashtag alignment for nodictatorinusa ...done.\n",
      "Getting hashtag alignment for 1MikeMerica ...done.\n",
      "Getting hashtag alignment for rondavt74 ...done.\n",
      "Getting hashtag alignment for TMHansen0528 ...done.\n",
      "Getting hashtag alignment for msbakerdw ...done.\n",
      "Getting hashtag alignment for ThomasH78937573 ...done.\n",
      "Getting hashtag alignment for MRMitchnet ...done.\n",
      "Getting hashtag alignment for jshoe2111 ...done.\n",
      "Getting hashtag alignment for rosiegee818 ...done.\n",
      "Getting hashtag alignment for rosiegee818 ...done.\n",
      "Getting hashtag alignment for rosiegee818 ...done.\n",
      "Getting hashtag alignment for 11groverbeac ...done.\n",
      "Getting hashtag alignment for Impeach40153700 ...done.\n",
      "Getting hashtag alignment for USANYCAL ...done.\n",
      "Getting hashtag alignment for never_martha ...done.\n",
      "Getting hashtag alignment for ArleneO99070647 ...done.\n",
      "Getting hashtag alignment for laniusd2011 ...done.\n",
      "Getting hashtag alignment for RefDemo ...done.\n",
      "Getting hashtag alignment for LKalawarny ...done.\n",
      "Getting hashtag alignment for roeorr ...done.\n",
      "Getting hashtag alignment for Samanthtics ...done.\n",
      "Getting hashtag alignment for NewfieTweeterer ...done.\n",
      "Getting hashtag alignment for GLORIANMICAH420 ...done.\n",
      "Getting hashtag alignment for cravenknowledge ...done.\n",
      "Getting hashtag alignment for JodiValeOnAir ...done.\n",
      "Getting hashtag alignment for LGMosson ...done.\n",
      "Getting hashtag alignment for Gwen580 ...done.\n",
      "Getting hashtag alignment for cravenknowledge ...done.\n",
      "Getting hashtag alignment for EYE_doubt_it ...done.\n",
      "Getting hashtag alignment for cravenknowledge ...done.\n",
      "Getting hashtag alignment for flinkinyc ...done.\n",
      "Getting hashtag alignment for SmilingDaisy2 ...done.\n",
      "Getting hashtag alignment for cravenknowledge ...done.\n",
      "Getting hashtag alignment for bsnbrysp8 ...done.\n",
      "Getting hashtag alignment for rondavt74 ...done.\n",
      "Getting hashtag alignment for cravenknowledge ...done.\n",
      "Getting hashtag alignment for paullb14u ...done.\n",
      "Getting hashtag alignment for Ripple7355 ...done.\n",
      "Getting hashtag alignment for kevargue ...done.\n",
      "Getting hashtag alignment for roxshep ...done.\n",
      "Getting hashtag alignment for sheri4c2 ...done.\n",
      "Getting hashtag alignment for jlm0354 ...done.\n",
      "Getting hashtag alignment for orzymann ...done.\n",
      "Getting hashtag alignment for DrJayHay ...done.\n",
      "Getting hashtag alignment for Poppie_field ...done.\n",
      "Getting hashtag alignment for bsnbrysp8 ...done.\n",
      "Getting hashtag alignment for penrosecurtis ...done.\n",
      "Getting hashtag alignment for rondavt74 ...done.\n",
      "Getting hashtag alignment for Tbark8Tj ...done.\n",
      "Getting hashtag alignment for msbakerdw ...done.\n",
      "Getting hashtag alignment for stefanie_wood ...done.\n",
      "Getting hashtag alignment for bighugewildRick ...done.\n",
      "Getting hashtag alignment for Mattophobia ...done.\n",
      "Getting hashtag alignment for RRNYNJCT ...done.\n",
      "Getting hashtag alignment for justhafaxjak ...done.\n",
      "Getting hashtag alignment for HaywardBrock ...done.\n",
      "Getting hashtag alignment for sheri4c2 ...done.\n",
      "Getting hashtag alignment for Stephy48393925 ...done.\n",
      "Getting hashtag alignment for UnrealJacklein ...done.\n",
      "Getting hashtag alignment for twinsfanchris ...done.\n",
      "Getting hashtag alignment for Don_Vito_08 ...done.\n",
      "Getting hashtag alignment for Harold_Laddd_ ...done.\n",
      "Getting hashtag alignment for indycatfan ...done.\n",
      "Getting hashtag alignment for HuntsberryBeth ...done.\n",
      "Getting hashtag alignment for armmoin ...done.\n",
      "Getting hashtag alignment for leftynest ...done.\n",
      "Getting hashtag alignment for jblanke1405 ...done.\n",
      "Getting hashtag alignment for MarieAnnaDvorak ...done.\n",
      "Getting hashtag alignment for StormH2Owoman ...done.\n",
      "Getting hashtag alignment for maudiefl ...done.\n",
      "Getting hashtag alignment for MiguelG87399322 ...done.\n",
      "Getting hashtag alignment for PPitstop66 ...done.\n",
      "Getting hashtag alignment for Melmack66 ...done.\n",
      "Getting hashtag alignment for GorGor71 ...done.\n",
      "Getting hashtag alignment for auryn_ayala ...done.\n",
      "Getting hashtag alignment for The_Ben_Reed ...done.\n",
      "Getting hashtag alignment for CarolATaylor10 ...done.\n",
      "Getting hashtag alignment for shershah54 ...done.\n",
      "Getting hashtag alignment for donnia8789 ...done.\n",
      "Getting hashtag alignment for chinagurucnxn ...done.\n",
      "Getting hashtag alignment for ChereeFranco ...done.\n",
      "Getting hashtag alignment for LumpkinsWesley ...done.\n",
      "Getting hashtag alignment for FarewellFred ...done.\n",
      "Getting hashtag alignment for LilPepper5 ...done.\n",
      "Getting hashtag alignment for larrycrabtre ...done.\n",
      "Getting hashtag alignment for Ahmedshykh786 ...done.\n",
      "Getting hashtag alignment for somethingothers ...done.\n",
      "Getting hashtag alignment for Harvilon_4G_LTE ...done.\n",
      "Getting hashtag alignment for slicknikkib0bby ...done.\n",
      "Getting hashtag alignment for Ronisweat ...done.\n",
      "Getting hashtag alignment for bsnbrysp8 ...done.\n",
      "Getting hashtag alignment for MaeWalk90880970 ...done.\n",
      "Getting hashtag alignment for richczar ...done.\n",
      "Getting hashtag alignment for savage138156 ...done.\n",
      "Getting hashtag alignment for msbakerdw ...done.\n",
      "Getting hashtag alignment for CarolATaylor10 ...done.\n",
      "Getting hashtag alignment for LynxSavage ...done.\n",
      "Getting hashtag alignment for shershah54 ...done.\n",
      "Getting hashtag alignment for MzVeeCee ...done.\n",
      "Getting hashtag alignment for hendyhasselbach ...done.\n",
      "Getting hashtag alignment for StormCilley ...done.\n",
      "Getting hashtag alignment for 1MikeMerica ...done.\n",
      "Getting hashtag alignment for HaroldLang16 ...done.\n",
      "Getting hashtag alignment for gml3897 ...done.\n",
      "Getting hashtag alignment for CaliGamer ...done.\n",
      "Getting hashtag alignment for HuntsberryBeth ...done.\n",
      "Getting hashtag alignment for suzannebfeehan ...done.\n",
      "Getting hashtag alignment for CraigDamon12 ...done.\n",
      "Getting hashtag alignment for StormH2Owoman ...done.\n",
      "Getting hashtag alignment for itskaybee__ ...done.\n",
      "Getting hashtag alignment for miggy420 ...done.\n",
      "Getting hashtag alignment for ltsnh1941 ...done.\n",
      "Getting hashtag alignment for elanasweaters ...done.\n",
      "Getting hashtag alignment for JoyceMe36019281 ...done.\n",
      "Getting hashtag alignment for nr1rizk ...done.\n",
      "Getting hashtag alignment for nhmartin ...done.\n",
      "Getting hashtag alignment for jabra707 ...done.\n",
      "Getting hashtag alignment for Hexter1288 ...done.\n",
      "Getting hashtag alignment for favpapa ...done.\n",
      "Getting hashtag alignment for Cameron69419949 ...done.\n",
      "Getting hashtag alignment for nrb352 ...done.\n",
      "Getting hashtag alignment for KimberlyBJones2 ...done.\n",
      "Getting hashtag alignment for JohnMorrissey26 ...done.\n",
      "Getting hashtag alignment for Lucifer_C_Z_A ...done.\n",
      "Getting hashtag alignment for doozy_22 ...done.\n",
      "Getting hashtag alignment for burf53 ...done.\n",
      "Getting hashtag alignment for Johnwjgt ...done.\n",
      "Getting hashtag alignment for JessicaMalLewis ...done.\n",
      "Getting hashtag alignment for Johnwjgt ...done.\n",
      "Getting hashtag alignment for mandakliger1 ...done.\n",
      "Getting hashtag alignment for JuliusRaab ...done.\n",
      "Getting hashtag alignment for KeithBurkhart3 ...done.\n",
      "Getting hashtag alignment for bdublosangeles ...done.\n",
      "Getting hashtag alignment for 1Hedl ...done.\n",
      "Getting hashtag alignment for psdaskas ...done.\n",
      "Getting hashtag alignment for mryder37 ...done.\n",
      "Getting hashtag alignment for SallyAONeil ...done.\n",
      "Getting hashtag alignment for jhhb6WQxNPoOiwg ...done.\n",
      "Getting hashtag alignment for Db123dryb2 ...done.\n",
      "Getting hashtag alignment for rod_everson ...done.\n",
      "Getting hashtag alignment for jolleyranchers7 ...done.\n",
      "Getting hashtag alignment for rod_everson ...done.\n",
      "Getting hashtag alignment for SueMarvin3 ...No file found for SueMarvin3 ; continuing.\n",
      "Getting hashtag alignment for 31073Pink ...done.\n",
      "Getting hashtag alignment for CarolATaylor10 ...done.\n",
      "Getting hashtag alignment for Kev777Oly ...done.\n",
      "Getting hashtag alignment for OregonCooper ...done.\n",
      "Getting hashtag alignment for pzoped ...done.\n",
      "Getting hashtag alignment for DStephenson2018 ...done.\n",
      "Getting hashtag alignment for TeaPartyLivesOn ...done.\n",
      "Getting hashtag alignment for shershah54 ...done.\n",
      "Getting hashtag alignment for CJPitt3 ...done.\n",
      "Getting hashtag alignment for CJPitt3 ...done.\n",
      "Getting hashtag alignment for cfairyfay ...done.\n",
      "Getting hashtag alignment for MEDICJAG ...done.\n",
      "Getting hashtag alignment for TekavecCarol ...done.\n",
      "Getting hashtag alignment for 8Abbottt ...done.\n",
      "Getting hashtag alignment for PrisonPsychRN ...done.\n",
      "Getting hashtag alignment for SusanneMavers ...done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting hashtag alignment for summerraine22 ...done.\n",
      "Getting hashtag alignment for JewlRaider ...done.\n",
      "Getting hashtag alignment for _TrumpTeens_ ...done.\n",
      "Getting hashtag alignment for alison_kovach ...done.\n",
      "Getting hashtag alignment for destilicious ...done.\n",
      "Getting hashtag alignment for FedUp1688 ...done.\n",
      "Getting hashtag alignment for bayazidhossain0 ...done.\n",
      "Getting hashtag alignment for tabtwil ...done.\n",
      "Getting hashtag alignment for nifermeister ...done.\n",
      "Getting hashtag alignment for CBirmantas ...done.\n",
      "Getting hashtag alignment for CarolATaylor10 ...done.\n",
      "Getting hashtag alignment for rea1Assange ...done.\n",
      "Getting hashtag alignment for islesss91 ...done.\n",
      "Getting hashtag alignment for hipple_jack ...done.\n",
      "Getting hashtag alignment for JohnMorrissey26 ...done.\n",
      "Getting hashtag alignment for MaryMay666666 ...done.\n",
      "Getting hashtag alignment for JohnMorrissey26 ...done.\n",
      "Getting hashtag alignment for janicerhines ...done.\n",
      "Getting hashtag alignment for bayazidhossain0 ...done.\n",
      "Getting hashtag alignment for shershah54 ...done.\n",
      "Getting hashtag alignment for FarewellFred ...done.\n",
      "Getting hashtag alignment for MzVeeCee ...done.\n",
      "Getting hashtag alignment for lightndns48 ...done.\n",
      "Getting hashtag alignment for Ladyjet02 ...done.\n",
      "Getting hashtag alignment for bsnbrysp8 ...done.\n",
      "Getting hashtag alignment for DarrinCarter7 ...done.\n",
      "Getting hashtag alignment for Ladyjet02 ...done.\n",
      "Getting hashtag alignment for tousjoursmax53 ...done.\n",
      "Getting hashtag alignment for mezikeen ...done.\n",
      "Getting hashtag alignment for TrumpFactNews ...done.\n",
      "Getting hashtag alignment for PDXReech ...done.\n",
      "Getting hashtag alignment for flip080708 ...done.\n",
      "Getting hashtag alignment for JCali1967 ...done.\n",
      "Getting hashtag alignment for cfairyfay ...done.\n",
      "Getting hashtag alignment for TXToasty ...done.\n",
      "Getting hashtag alignment for mbeavenhausen ...done.\n",
      "Getting hashtag alignment for 7axles ...done.\n",
      "Getting hashtag alignment for 7axles ...done.\n",
      "Getting hashtag alignment for fvmcgillicuddy ...done.\n",
      "Getting hashtag alignment for Jessewayne_Bruh ...done.\n",
      "Getting hashtag alignment for bsnbrysp8 ...done.\n",
      "Getting hashtag alignment for General_Bats ...done.\n",
      "Getting hashtag alignment for MSpencerDavidso ...done.\n",
      "Getting hashtag alignment for pzoped ...done.\n",
      "Getting hashtag alignment for IRSGODDESS ...done.\n",
      "Getting hashtag alignment for mdrummond43 ...done.\n",
      "Getting hashtag alignment for KarenLWorlock ...done.\n",
      "Getting hashtag alignment for CodyKinter ...done.\n",
      "Getting hashtag alignment for bonsaibean ...done.\n",
      "Getting hashtag alignment for EricaGeoy ...done.\n",
      "Getting hashtag alignment for SkillsLA ...done.\n",
      "Getting hashtag alignment for susanbratrude ...done.\n",
      "Getting hashtag alignment for Cameron69419949 ...done.\n",
      "Getting hashtag alignment for realtorred2 ...done.\n",
      "Getting hashtag alignment for mariachamberlin ...done.\n",
      "Getting hashtag alignment for ghenry5701 ...done.\n",
      "Getting hashtag alignment for uniquefoliage_ ...done.\n",
      "Getting hashtag alignment for CarolATaylor10 ...done.\n",
      "Getting hashtag alignment for bsnbrysp8 ...done.\n",
      "Getting hashtag alignment for XplodedSynapses ...done.\n",
      "Getting hashtag alignment for ghenry5701 ...done.\n",
      "Getting hashtag alignment for kellinicolef ...done.\n",
      "Getting hashtag alignment for General_Bats ...done.\n",
      "Getting hashtag alignment for officersick ...done.\n",
      "Getting hashtag alignment for IRSGODDESS ...done.\n",
      "Getting hashtag alignment for CarlOscarNordi1 ...done.\n",
      "Getting hashtag alignment for Goathouse53 ...done.\n",
      "Getting hashtag alignment for Arthurswench ...done.\n",
      "Getting hashtag alignment for pureBelter ...done.\n",
      "Getting hashtag alignment for __TJM ...done.\n",
      "Getting hashtag alignment for moebetta1950 ...done.\n",
      "Getting hashtag alignment for RedBVWarZone1 ...done.\n",
      "Getting hashtag alignment for the_Real_briguy ...done.\n",
      "Getting hashtag alignment for WKitsune ...done.\n",
      "Getting hashtag alignment for peebsnjay ...done.\n",
      "Getting hashtag alignment for tainttaster ...done.\n",
      "Getting hashtag alignment for Grimmkitty47 ...done.\n",
      "Getting hashtag alignment for PDXReech ...done.\n",
      "Getting hashtag alignment for flip080708 ...done.\n",
      "Getting hashtag alignment for JCali1967 ...done.\n",
      "Getting hashtag alignment for cfairyfay ...done.\n",
      "Getting hashtag alignment for TXToasty ...done.\n",
      "Getting hashtag alignment for mbeavenhausen ...done.\n",
      "Getting hashtag alignment for 7axles ...done.\n",
      "Getting hashtag alignment for 7axles ...done.\n",
      "Getting hashtag alignment for fvmcgillicuddy ...done.\n",
      "Getting hashtag alignment for Jessewayne_Bruh ...done.\n",
      "Getting hashtag alignment for bsnbrysp8 ...done.\n",
      "Getting hashtag alignment for General_Bats ...done.\n",
      "Getting hashtag alignment for MSpencerDavidso ...done.\n"
     ]
    }
   ],
   "source": [
    "alignments = []\n",
    "\n",
    "for u in user_list:\n",
    "    try:\n",
    "        print(\"Getting hashtag alignment for\", u, \"...\", end=\"\")\n",
    "        alignments.append(get_hashtag_alignment(u))\n",
    "        print(\"done.\")    \n",
    "    except FileNotFoundError:\n",
    "        alignments.append(\"N/A\")\n",
    "        print(\"No file found for\", u, \"; continuing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Adding the hashtag feature vector to the database </b>\n",
    "\n",
    "Using the list created in the previous step, we add the feature vector to our database with the column title \"hashtag\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_donald_replies['hashtag'] = alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Saving the new database as a csv </b>\n",
    "\n",
    "Finally, we write the new database to a csv file and load it in for further work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_donald_replies.to_csv(\"ddr_following_and_hashtag.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Reading in the database from the saved csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>following</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>comp_sentiment</th>\n",
       "      <th>donald_neg_sentiment</th>\n",
       "      <th>donald_pos_sentiment</th>\n",
       "      <th>donald_neu_sentiment</th>\n",
       "      <th>donald_comp_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "      <td>-7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \\\n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...   \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ   \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia   \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s   \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!   \n",
       "\n",
       "   following  hashtag  neg_sentiment  pos_sentiment  neu_sentiment  \\\n",
       "0         -8      0.0          0.536          0.119          0.345   \n",
       "1         -7      3.0          0.000          0.000          1.000   \n",
       "2         -1      2.0          0.000          0.286          0.714   \n",
       "3         -3      0.0          0.000          0.000          1.000   \n",
       "4         -3      0.0          0.000          0.000          1.000   \n",
       "\n",
       "   comp_sentiment  donald_neg_sentiment  donald_pos_sentiment  \\\n",
       "0          -0.871                   0.0                 0.486   \n",
       "1           0.000                   0.0                 0.486   \n",
       "2           0.340                   0.0                 0.486   \n",
       "3           0.000                   0.0                 0.486   \n",
       "4           0.000                   0.0                 0.486   \n",
       "\n",
       "   donald_neu_sentiment  donald_comp_sentiment  \n",
       "0                 0.514                 0.9229  \n",
       "1                 0.514                 0.9229  \n",
       "2                 0.514                 0.9229  \n",
       "3                 0.514                 0.9229  \n",
       "4                 0.514                 0.9229  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_donald_replies = pd.read_csv(\"ddr_following_and_hashtag.csv\", index_col=0, dtype={'reply_id':str})\n",
    "data_donald_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Adding the sentiments of the original tweets to the table </b>\n",
    "\n",
    "To consolidate all the information we want to use in our machine learning model, we add the sentiments associated with Trump's original tweet to each of the reply rows. So now not only do the rows include the sentiments relating to the reply tweet, but also relating to the tweet that is being replied to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "donald_neg_sentiments = []\n",
    "donald_pos_sentiments = []\n",
    "donald_neu_sentiments = []\n",
    "donald_comp_sentiments = []\n",
    "\n",
    "\n",
    "for _, x in data_donald_replies.iterrows():\n",
    "    orig = x['reply_id']\n",
    "    \n",
    "    matches = data_donald[data_donald['tweet_id'] == x['reply_id']]\n",
    "    \n",
    "\n",
    "    for _, y in matches.iterrows():\n",
    "        donald_neg_sentiments.append(y['neg_sentiment'])\n",
    "        donald_pos_sentiments.append(y['pos_sentiment'])\n",
    "        donald_neu_sentiments.append(y['neu_sentiment'])\n",
    "        donald_comp_sentiments.append(y['comp_sentiment'])\n",
    "        \n",
    "data_donald_replies['donald_neg_sentiment'] = donald_neg_sentiments\n",
    "data_donald_replies['donald_pos_sentiment'] = donald_pos_sentiments\n",
    "data_donald_replies['donald_neu_sentiment'] = donald_neu_sentiments\n",
    "data_donald_replies['donald_comp_sentiment'] = donald_comp_sentiments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Saving the updated table to a csv and reading it in from the csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_donald_replies.to_csv(\"compared_sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>following</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>comp_sentiment</th>\n",
       "      <th>donald_neg_sentiment</th>\n",
       "      <th>donald_pos_sentiment</th>\n",
       "      <th>donald_neu_sentiment</th>\n",
       "      <th>donald_comp_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "      <td>-7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \\\n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...   \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ   \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia   \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s   \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!   \n",
       "\n",
       "   following  hashtag  neg_sentiment  pos_sentiment  neu_sentiment  \\\n",
       "0         -8      0.0          0.536          0.119          0.345   \n",
       "1         -7      3.0          0.000          0.000          1.000   \n",
       "2         -1      2.0          0.000          0.286          0.714   \n",
       "3         -3      0.0          0.000          0.000          1.000   \n",
       "4         -3      0.0          0.000          0.000          1.000   \n",
       "\n",
       "   comp_sentiment  donald_neg_sentiment  donald_pos_sentiment  \\\n",
       "0          -0.871                   0.0                 0.486   \n",
       "1           0.000                   0.0                 0.486   \n",
       "2           0.340                   0.0                 0.486   \n",
       "3           0.000                   0.0                 0.486   \n",
       "4           0.000                   0.0                 0.486   \n",
       "\n",
       "   donald_neu_sentiment  donald_comp_sentiment  \n",
       "0                 0.514                 0.9229  \n",
       "1                 0.514                 0.9229  \n",
       "2                 0.514                 0.9229  \n",
       "3                 0.514                 0.9229  \n",
       "4                 0.514                 0.9229  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_donald_replies = pd.read_csv(\"compared_sentiments.csv\", index_col=0, dtype={'reply_id':str})\n",
    "data_donald_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loading target values </b>\n",
    "\n",
    "Since the NLTK Sentiment Analyzer doesn't do a very good job of accounting for sarcasm, we want to use machine learning to see if our hashtag and following features can work alongside the analyzer to produce better predictions. Our plan is to use a scikit-learn SVM to make these predictions. We'll train the SVM with our hashtag and following features, as well as with the NLTK Sentiment Analyses of that particular tweet and the presidential tweet to which it is replying.\n",
    "\n",
    "The target values of our SVM will be classifications we did by hand and stored in a csv file. We labeled a tweet -1 if it seemed negative, 0 if it seemed neutral, and 1 if it seemed positive. Below, we load our csv file, and proceed to add our classification labels to the full pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  classification\n",
       "0  @realDonaldTrump Resign before you are impeach...              -1\n",
       "1          @realDonaldTrump  https://t.co/tuQNvmQYEZ               0\n",
       "2    @realDonaldTrump Now go play roulette in Russia              -1\n",
       "3          @realDonaldTrump  https://t.co/sIPqjPoX3s               0\n",
       "4  @realDonaldTrump You know nothing about football!              -1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified = pd.read_csv(\"compared_sentiments_classified.csv\", index_col=0)\n",
    "classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>following</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>comp_sentiment</th>\n",
       "      <th>donald_neg_sentiment</th>\n",
       "      <th>donald_pos_sentiment</th>\n",
       "      <th>donald_neu_sentiment</th>\n",
       "      <th>donald_comp_sentiment</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "      <td>-7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \\\n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...   \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ   \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia   \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s   \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!   \n",
       "\n",
       "   following  hashtag  neg_sentiment  pos_sentiment  neu_sentiment  \\\n",
       "0         -8      0.0          0.536          0.119          0.345   \n",
       "1         -7      3.0          0.000          0.000          1.000   \n",
       "2         -1      2.0          0.000          0.286          0.714   \n",
       "3         -3      0.0          0.000          0.000          1.000   \n",
       "4         -3      0.0          0.000          0.000          1.000   \n",
       "\n",
       "   comp_sentiment  donald_neg_sentiment  donald_pos_sentiment  \\\n",
       "0          -0.871                   0.0                 0.486   \n",
       "1           0.000                   0.0                 0.486   \n",
       "2           0.340                   0.0                 0.486   \n",
       "3           0.000                   0.0                 0.486   \n",
       "4           0.000                   0.0                 0.486   \n",
       "\n",
       "   donald_neu_sentiment  donald_comp_sentiment  classification  \n",
       "0                 0.514                 0.9229              -1  \n",
       "1                 0.514                 0.9229               0  \n",
       "2                 0.514                 0.9229              -1  \n",
       "3                 0.514                 0.9229               0  \n",
       "4                 0.514                 0.9229              -1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_donald_replies['classification'] = classified['classification']\n",
    "data_donald_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Splitting the data into training and testing data </b>\n",
    "\n",
    "Our SVM needs data with which to be trained and data with which to be tested. We are aiming for an 80/20 training/testing ratio. Since we are basing this experiment on a total of 13 of President Trump's tweets and their replies, we'll use 11 of those tweets and their replies to train the SVM, and the remaining 2 to test it.\n",
    "\n",
    "Below, we first separate the first 11 and the remaining 2 IDs of President Trump's tweets into two separate lists. Then, we use those lists to split the actual DataFrame of replies into two tables according to the tweet they're replying to. Finally, we select the columns of each table that we want to use. For X values, we want the following feature, the hashtag feature, each of the features predicted for that particular tweet by the NLTK Sentiment Analyzer, and each of the features predicted for the corresponding presidential tweet by the same analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_tweets_ids = []\n",
    "\n",
    "for _, x in data_donald.iterrows():\n",
    "    if not(x['tweet_id'] in trump_tweets_ids):\n",
    "        trump_tweets_ids.append(x['tweet_id'])\n",
    "        \n",
    "training_trump_tweets_ids = trump_tweets_ids[0:10]\n",
    "testing_trump_tweets_ids = trump_tweets_ids[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_table = data_donald_replies[(data_donald_replies['reply_id'] == training_trump_tweets_ids[0]) | \\\n",
    "                                        (data_donald_replies['reply_id'] == training_trump_tweets_ids[1]) | \\\n",
    "                                     (data_donald_replies['reply_id'] == training_trump_tweets_ids[2]) | \\\n",
    "                                    (data_donald_replies['reply_id'] == training_trump_tweets_ids[3]) | \\\n",
    "                                     (data_donald_replies['reply_id'] == training_trump_tweets_ids[4]) | \\\n",
    "                                     (data_donald_replies['reply_id'] == training_trump_tweets_ids[5]) | \\\n",
    "                                     (data_donald_replies['reply_id'] == training_trump_tweets_ids[6]) | \\\n",
    "                                     (data_donald_replies['reply_id'] == training_trump_tweets_ids[7]) | \\\n",
    "                                     (data_donald_replies['reply_id'] == training_trump_tweets_ids[8]) | \\\n",
    "                                     (data_donald_replies['reply_id'] == training_trump_tweets_ids[9])]\n",
    "\n",
    "testing_table = data_donald_replies[(data_donald_replies['reply_id'] == testing_trump_tweets_ids[0]) | \\\n",
    "                                    (data_donald_replies['reply_id'] == testing_trump_tweets_ids[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>following</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>comp_sentiment</th>\n",
       "      <th>donald_pos_sentiment</th>\n",
       "      <th>donald_neg_sentiment</th>\n",
       "      <th>donald_neu_sentiment</th>\n",
       "      <th>donald_comp_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   following  hashtag  neg_sentiment  pos_sentiment  neu_sentiment  \\\n",
       "0         -8      0.0          0.536          0.119          0.345   \n",
       "1         -7      3.0          0.000          0.000          1.000   \n",
       "2         -1      2.0          0.000          0.286          0.714   \n",
       "3         -3      0.0          0.000          0.000          1.000   \n",
       "4         -3      0.0          0.000          0.000          1.000   \n",
       "\n",
       "   comp_sentiment  donald_pos_sentiment  donald_neg_sentiment  \\\n",
       "0          -0.871                 0.486                   0.0   \n",
       "1           0.000                 0.486                   0.0   \n",
       "2           0.340                 0.486                   0.0   \n",
       "3           0.000                 0.486                   0.0   \n",
       "4           0.000                 0.486                   0.0   \n",
       "\n",
       "   donald_neu_sentiment  donald_comp_sentiment  \n",
       "0                 0.514                 0.9229  \n",
       "1                 0.514                 0.9229  \n",
       "2                 0.514                 0.9229  \n",
       "3                 0.514                 0.9229  \n",
       "4                 0.514                 0.9229  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_X = training_table[['following', 'hashtag', 'neg_sentiment', 'pos_sentiment', 'neu_sentiment', \\\n",
    "                                    'comp_sentiment', 'donald_pos_sentiment', 'donald_neg_sentiment', \\\n",
    "                                  'donald_neu_sentiment','donald_comp_sentiment']]\n",
    "training_data_y = training_table[['classification']]\n",
    "testing_data_X = testing_table[['following', 'hashtag', 'neg_sentiment', 'pos_sentiment', 'neu_sentiment', \\\n",
    "                                'comp_sentiment', 'donald_pos_sentiment', 'donald_neg_sentiment', \\\n",
    "                                'donald_neu_sentiment','donald_comp_sentiment']]\n",
    "testing_data_y = testing_table[['classification']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Encoding data and creating our SVM </b>\n",
    "\n",
    "Because we have used pandas for all of our data manipulation thus far, and also wish to use sklearn for our SVM, we're going to have to use sklearn's LabelEncoder to get the pandas DataFrames data into a format sklearn knows how to deal with. The LabelEncoder converts data into data sklearn can understand. \n",
    "\n",
    "The only difficulty with the LabelEncoder is that it will change the way our machine learning data looks. For example, it will convert the -1 to 1 scale we used to label our data with a 0 to 2 scale. While this will change the exact appearance of the data when we visualize it, it will still show the same relationships between all of our data. This will be more apparent in our visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, svm\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(training_data_X.apply(le1.fit_transform), training_data_y.apply(le2.fit_transform))\n",
    "predictions = clf.predict(testing_data_X.apply(le1.fit_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Visualizing our predictions </b>\n",
    "\n",
    "Finally, we use pyplot to visualize what the SVM has predicted the sentiment of the testing replies to be. In blue we have plotted the actual sentiments of the tweets as we classified them by hand earlier. In red is a line showing the SVM predictions for the sentiments. \n",
    "\n",
    "We have plotted the sentiments of the responses (both actual and predicted) against the composite sentiments of President Trump's original tweets. That will give us a clear idea what kind of relationship there is between the sentiment of the original tweet and the sentiment of the reply tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmYHFW5x/Hvj5CwhJ3EsCaBgChI\nQAiyryJeFkGRiAoIXgRRr6goi4IauHJF0IssIgaBCMgOCqgYQEhAVhMMJKyXPexZ2MKe8N4/zhlS\n6fT01GSmqzPD7/M880xtXfWe2t6qU9WnFRGYmZkt0uoAzMxs4eCEYGZmgBOCmZllTghmZgY4IZiZ\nWeaEYGZmgBPCfCQNlRSSFs3910rav4LljpJ0QbOXU4akWZLWbHUc3UXSEpKukfSKpMtaHY81V0fH\nkqQnJO1YZUw9RY9MCHmDvplPXC9IOlfSUs1YVkTsHBF/KBlT03YyST+S9Hgu89OSLumm+Y6T9LXi\nsIhYKiIe6475dzKWZq3DvYBBwIoRMbLOckdJejev25cl3SZp8ybE0WPki6K1FvCzbRdVswrH6F8k\nfaq74+yqvO1HdWL6wYVyzcrlfL3Qv3UTw22LYfG83NW6e949MiFkn4mIpYCNgE2AY2onUNKTywhA\nvkPZD9gxl3kE8I/WRtWjDAEejojZDaa5JK/bAcBNgO8kum65vE43AK4H/iTpgNaG1DUR8VS+YFoq\nlw1gg8KwW1oaYBf1+JNlRDwDXAt8DN6/4j1e0q3AG8CakpaVdLak5yQ9I+lnkvrk6ftI+qWk6ZIe\nA3Ytzr/2ClrSQZIekPSapPslbSTpfGAwcE2+SjgiT7tZvtp8WdI9krYrzGcNSePzfK4nnYjaswkw\nNiIezWV+PiJGF+bVqHwHSPpnLuNL+S5j5zzueGBr4PQc9+l5+PtXh5LGSDojV53NknSrpJUk/TrP\n70FJHy/EsoqkKyRNy8s6tDBulKRLJZ2Xy32fpBF53HzrMF8JXSBpRl6H/5I0qN4KkvTRvK1ezvPd\nPQ8/FvgJsHee74EN1jM5afwRWFXSwML8d5M0qXAHMbww7si83l+T9JCkTxbKe7mkS/K4uyVt0FHM\nhfX+G0l/zZ+9U9KwPE6STpb0olI12L2S2vb/xfK2fkrpyvxMSUvkcQOUrtRfljRT0i2qc8Ek6ebc\neU9eZ3vn4QdJeiR/9mpJqzRal4V1+nxEnAKMAn7RtswFLX8ef4qkqZJelTRRDa7MJe0n6cm8Hx3d\nYLpS66eRXKYXC/0XSHqq0H+5pENy9wr5WHg+l+WnxeVJ+nren2bm9bBqHtW2fR7K2+ezSsfk33Ps\nMyTd2Jm43xcRPe4PeIJ0tQywOnAf8N+5fxzwFLAesCjQF/gz8DugP/Ah4C7g63n6Q4AH83xWIF0d\nBrBoYX5fy90jgWdIJ2gBawFDamPK/asCM4BdSIn3U7l/YB5/O/C/wGLANsBrwAXtlHdfYCZwOOnu\noE/N+EblOwB4FzgI6AN8A3gWUG35CvMLYK3cPQaYDmwMLA7cCDwOfCXP72fATXnaRYCJpBNwP2BN\n4DHg03n8KOCtvE76AD8H7qi3XXP/14FrgCXz9BsDy9RZP32BR4Af5eXukNfnOoXl1l23tePz50/I\nZW7bBzYCXgQ2zXHsn2NdDFgHmAqskqcdCgwrzPddUpVVX+AHed31LRHzmLzNP0Haj/8IXJzHfTqv\n5+VI++FHgZXzuF8DV5P25aXz+vt5Hvdz4MzC8rdu2w/qrJP394Hcv0NeJxvlcp8G3NzOZ4dSOIYK\nw9fMwz/alfIXjokV87jvA88Di9fZnusCs0jH2GKkY242hf2sMM/S66e99ZSHvQCsl7sfz39rFMZ9\nNHdfm9fjksDKwL+B/fO4LwIPAB/OsRSPs8XzclcrLPNk4JS8PvoB2yzQubVZJ+1m/pEOxlnAy8CT\nwBnAEnncOOC4wrSDgLfbxudhXyqs3BuBQwrjdqL9hDAW+E6DmIonsyOB82umGUs6mQzOO2X/wrgL\naXzS2ge4AXidlFiOKlm+A4BHCuOWzOVbqbZ89XZy0oF5VmHct4EHCv3rAy/n7k2Bp2rm9UPg3Jh7\noN5QGLcu8GaDdfifwG3A8A72h61JJ4RFCsMuAkYVlttRQngn709z8vrdrjD+t+QLjsKwh4BtSRcF\nLwI7An3rzLeY8BYBnsvxdhTzGOD3hXG7AA/m7h2Ah4HNaj6vvH8MKwzbHHg8dx8HXEXNCayddVKb\nEM4GTiz0L0VKdkPrfHYo9RNC24lsy66Uv514XyJV3cyzvUkXJ8VE0j9v63oJofT6aW895WGXAd/M\n6+Fe4FTScfhR4IU8zZC8rfoWPvdV4NrcfROwT2Fc37y+B1E/IZyYl7tm2djr/fXkKqPPRsRyETEk\nIr4ZEW8Wxk0tdA8hrczn8u3Uy6Sr6Q/l8avUTP9kg2WuDjxaMr4hwMi2ZeblbkW6ElgFeCkiXi+5\nXCLijxGxI+mq8BDgOEmfLlE+SAde23zeyJ2deQj/QqH7zTr9bfMaAqxSU+YfkXbi+WIhVektrvxG\nVx3nk5LoxZKelXSipL51plsFmBoR7xWGPUm6Syvr0ohYLsc6hXQ30mYI8P2acq1Ouit4BPgu6ST0\noqSLa6pS3t+3cnxP53jLxFy7rpbK87kROB34DfCCpNGSlgEGkhL+xEKcf8/DAU4iXZVfJ+kxSUd1\nYv2sQmEfjYhZpMTZmXXcNu1MulB+AEnfV6q6fSWXc1nqV7vOc3znY25GO/F1Zf0UjQe2I92VjCdd\ndG2b/9qqe4aQTuzTCtvqFOYeK0OAMwvjppEuItt7kHw86c7/plytd9iCBN6TE0IjUeieSrqCHpAT\nyHIRsUxErJfHP0c6uNsMbjDfqcCwdsZFTf9U0h3CcoW//hFxQl7m8pL6l1zu3IVEvBsRl5GuPD5W\nonwdzrLkdGVMJV2NFsu8dETssiCx5LIeGxHrAlsAu5Gqqmo9C6xeU987mFS91ykRMZ1UVTVK0sp5\n8FTg+JpyLRkRF+XPXBgRW5EO4gB+UZjl+/tWjm+1HG+XYo6IUyNiY1LV6IdJ1YnTSQl6vUKcy0Z+\n+BkRr0XE9yNiTeAzwGHKzztKeDaXr60s/UlVNp1Zx58j3U09RBfKn58XHAl8AVg+J/JXSHdIteY5\nviUtmeOeTxfXT9F40sm/LSHcnLu3zf2Q9qlZbfEXjtuNCuMPqNnnloiIidQ5ZiPilYj4TkQMAT4P\nHCNpy84G3lsTwvsi4jngOuBXkpaRtIikYZK2zZNcChwqaTVJywONrgp+D/xA0sZK1pLUdpC8QKoj\nbXMB8BlJn1Z6cL24pO0krRYRTwITgGMl9ZO0FWkHrEvpwfCukpbO8e9MOhHcWaJ8HamNuyvuAl5V\nesi6RC73xyRtsiCxSNpe0vpKD8hfJd0yz6nzuTtJt99HSOqr9PD+M8DFC1KIiHiQdGdyRB50FnCI\npE3zdu9f2B7rSNpB0mKk5yNv1sS4saQ9813Qd0nJ+46uxCxpkxxL3zyPt4A5+Wr7LOBkSR/K066a\n7yTbHoyvJUmk9TmH+usT5t8vLgS+KmnDXNb/Ie1/T5SId5Ck/wJ+Cvwwx9mVbbY06Wp5GrCopJ8A\ny7Qz7eXAbpK2ktSPVC1U97zXyfXTyBTSs6aRpOcs00l3OLuSE0JEPE7aD04sHNdr53MBpGcZx0ha\nJ8e2vKTP58++TUqAxWNld6UXVZTHLVDsvT4hZF8hPWi5n1TXeDmp6gbSATQWuAe4G7iyvZnkK/Pj\nSQfHa6SHuSvk0T8nbcCXJf0gIqYCe5CqTKaRMv7hzF3nXybVuc8kHSjnNYj/1Tyfp0j13CcC34iI\nf5YoX0dOAfZSemPo1JKfqSsi5pAO6g1JD9Kmk5LosiVnMc86BFYileVV0gO28aREW7vcd4DdgZ3z\nMs8AvpJP7AvqJOBgSR+KiAmkh/Knk9bvI6Q6YUgPKtseQj9Pqqr7UWE+VwF758/tB+yZ73y6EvMy\npP32JVI1ywzgl3nckTm+OyS9SnrutE4et3bun0V6qeGMiBjXzjJGAX/I2+ILEfEP4MfAFaSr7mGk\nB5+NvCzpdWAy6RnAyIg4B7q8zcaSHsg+nMv/FvNW+74vIu4DvkU6Zp8jrbOn25lvZ9ZPuyJV6t8C\nPBsRbW8cjSdd0EwpTPolUhXwg6TzwCXkKqN893k6cGXejpNIL6a0+QlwWd4+u5OeT4wjnZduBn4Z\nEXd0Nva2N03MrJspfeFprYjYt9WxmJXxQblDMDOzDjghmJkZ4CojMzPLfIdgZmZA+ppzjzFgwIAY\nOnRoq8MwM+tRJk6cOD0iBnY0XY9KCEOHDmXChAmtDsPMrEeR1LAlhDauMjIzM8AJwczMMicEMzMD\nnBDMzCxzQjAzM8AJwczMspYmBEnnKP0u7JSOpzYzs2Zq9fcQxpCaeG3U9HO32+es27n10Znv9285\nbAX+eNDmVYZgZrbQaekdQkTcTGoHvDK1yQDg1kdnss9Zt1cZhpnZQucD9wyhNhl0NNzM7INioU8I\nkg6WNEHShGnTprU6HDOzXmuhTwgRMToiRkTEiIEDO2ybyczMFtBCnxC625bDVujUcDOzD4pWv3Z6\nEenHrNeR9LSkA5u9zD8etPl8J3+/ZWRm1uLXTiPiS61Yrk/+Zmbz+8BVGZmZWX1OCGZmBjghmJlZ\n5oRgZmaAE4KZmWVOCGZmBjghmJlZ5oRgZmaAE4KZmWVOCGZmBjghmJlZ5oRgZmaAE4KZmWVOCGZm\nBjghmJlZ5oRgZmaAE4KZmWVOCGZmBjghmJlZ1mFCkDSmzDAzM+vZytwhDC/2SFoE2KQ54ZiZWau0\nmxAkHSnpJWC4pJmSXsr904G/VRahmZlVotEdwonAQODk/H8AMCAiVoiIw6sIzszMqtNuQohkNnAE\nMBI4MiLmSFpN0saVRWhmZpUo8wzhNGB7YL/c/wZwZtMiMjOzlli0xDRbRMRGkv4NEBEzJfVrclxm\nZlaxMncI7+Y3iwJA0orAe02NyszMKlcmIfwGuAIYKOlY4J/AL5oalZmZVa7DKqOIOE/SRGBHQMDI\niJjS9MjMzKxSZZuuWBp4KSJ+DTwnaXATYzIzsxbo8A5B0jHAlsAw4DxgceBCYKvmhmZmZlUqc4ew\nF7AL8DpARDwDLNPMoMzMrHplEsLbERHMfctoyeaGZGZmrVAmIVwp6TfAspK+ClwHnNPcsMzMrGpl\n3jL6haSdgXeADYDjI+LapkdmZmaVKvNQ+SvALU4CZma9W5mmKz4CfE3SKsBdwC2kBOHvIpiZ9SId\nPkOIiB9FxDbA+sAdwA+Be5odmJmZVatMldFRpO8cLE9KBEeR7hLMzKwXKVNl9GXgLeAqYDxwZ0S8\n29SozMyscmWqjIYDOwH3Ap8Bpkga1+S4zMysYmWqjD4CbA1sC3wCeAG4rclxmZlZxcpUGZ1Cqioa\nDRwYEW83NyQzM2uFdhOCpDERcUBEfLrKgMzMrDUaPUMYXlkUZmbWco2qjJaU9HHSj+LMJyLubk5I\nZmbWCo0SwqrAr6ifEALYoSkRmZlZSzRKCI9EhE/6ZmYfEGV/QtPMzHq5RgnhyMqiMDOzlms3IUTE\ndVUGYmZmreUqIzMzAzqRECT1b2YgZmbWWh0mBElbSLofeCD3byDpjKZHZmZmlSpzh3Ay8GlgBkBE\n3ANs08ygzMyseqWqjCJias2gOU2IxczMWqhMa6dTJW0BhKR+wKHk6iMzM+s9ytwhHAJ8i9SUxdPA\nhrnfzMx6kQ7vECJiOrBPBbGYmVkLlXnL6ERJy0jqK+kfkqZL2reK4MzMrDplqox2iohXgd1IVUYf\nBg5valRmZla5Mgmhb/6/C3BRRMxsYjxmZtYiZd4yukbSg8CbwDclDQTeam5YZmZWtQ7vECLiKGBz\nYEREvAu8DuzR7MDMzKxaZe4QAD4KDJVUnP68JsRjZmYt0mFCkHQ+MAyYxNxvKAdOCGZmvUqZO4QR\nwLoREc0OxszMWqfMW0ZTgJWaHYiZmbVWmTuEAcD9ku4C3m4bGBG7Ny0qMzOrXJmEMKrZQZiZWeuV\nactovKRBwCZ50F0R8WJzwzIzs6qVacvoC8BdwEjgC8CdkvZqdmBmZlatMlVGRwObtN0V5G8q3wBc\n3szAzMysWmXeMlqkpopoRsnPmZlZD1LmDuHvksYCF+X+vYG/NS8kMzNrhTIPlQ+XtCewFSBgdET8\nqemRmZlZpcq2ZXQbqdmK94B/NS8cMzNrlTJvGX2N9JbR54C9gDsk/WezAzMzs2qVuUM4HPh4RMwA\nkLQi6Y7hnGYGZmZm1SrzttDTwGuF/teAqc0Jx8zMWqXMHcIzpC+jXUVq9noP4C5JhwFExP82MT4z\nM6tImYTwaP5rc1X+v3T3h2NmZq1S5rXTY9u6JS0CLBURrzY1KjMzq1yZt4wulLSMpP7A/cBDkg5v\nfmhmZlalMg+V1813BJ8lfUN5MLBfU6MyM7PKlUkIfSX1JSWEqyLiXdLDZTMz60XKJITfAU8A/YGb\nJQ0B/AzBzKyXKfNQ+VTg1MKgJyVt37yQzMysFco8VB4k6WxJ1+b+dYH9mx6ZmZlVqsz3EMYA55J+\nKAfgYeAS4OyuLlzSfwCnAH2A30fECV2dZxmbHn89L7z2zvv9g5bux51Hf6qKRZuZtWuNo/46zwNa\nAY+fsGtlyy/zDGFARFxKaumUiJhNavm0SyT1AX4D7AysC3wp3300VW0yAHjhtXfY9Pjrm71oM7N2\n1SYDSG/vrHHUXyuLocwdwuu5QbsAkLQZ8Eo3LPsTwCMR8Vie78WkZjHu74Z5t6stGZx/8TFs/eSk\neUce08wlm5m17/Ga/qFH/gWo9pXOMgnhMOBqYJikW4GBwMhuWPaqzNtI3tPAprUTSToYOBhg8ODB\n3bBYMzOrp8xbRndL2hZYh1Sl9VD+LkJXqd7i6ix/NDAaYMSIEd2WLPf74s/mG/ZEhXV1ZmZFQyus\nGmpPmWcIRMTsiLgvIqYA20nqjgr3p4HVC/2rAc92w3wbGrR0v04NNzOrQr0r5EbDm6HdhCBpB0kP\nS5ol6QJJ60qaAJwA/LYblv0vYG1Ja0jqB3yRVDXVVHce/an5Tv5+y8jMWu3xE3ad7+Rf9VtGjaqM\nfkWqu7+d9CbQHcCPI+KU7lhwRMyW9F/AWNJrp+dExH3dMe+O+ORvZgujKk/+9TRKCBER43L3nyVN\n665kUFjA30gN5pmZWYs1SgjLSdqz0K9if0Rc2bywzMysao0SwnjgM+30B+CEYGbWi7SbECLiq1UG\nYmZmrVXqtVMzM+v9nBDMzAxo/D2Ekfn/GtWFY2ZmrdLoDuGH+f8VVQRiZmat1egtoxmSbgLWkDTf\nN4gjYvfmhWVmZlVrlBB2BTYCzid9a9nMzHqxRq+dvgPcIWmLiJgmaek0OGZVF56ZmVWlzFtGgyT9\nG5gC3C9poqSPNTkuMzOrWJmEMBo4LCKGRMRg4Pt5mJmZ9SJlEkL/iLiprSc3eNe/aRGZmVlLlPkJ\nzcck/Zj0cBlgX+b/+U8zM+vhytwh/Cfpd5SvzH8DALdzZGbWy5T5TeWXgEMriMXMzFrIbRmZmRng\nhGBmZlmHCUHSlmWGmZlZz1bmDuG0ksPMzKwHa/ehsqTNgS2AgZIOK4xaBujT7MDMzKxajd4y6gcs\nladZujD8VWCvZgZlZmbVa9S43XhgvKQxEfFkhTGZmVkLlPmm8mKSRgNDi9NHxA7NCsrMzKpXJiFc\nBpwJ/B6Y09xwzMysVcokhNkR8dumR2JmZi1V5rXTayR9U9LKklZo+2t6ZGZmVqkydwj75/+HF4YF\nsGb3h2NmZq1SpnG7NaoIxMzMWqtM0xVLSjomv2mEpLUl7db80MzMrEplniGcC7xD+tYywNPAz5oW\nkZmZtUSZhDAsIk4E3gWIiDcBNTUqMzOrXJmE8I6kJUgPkpE0DHi7qVGZmVnlyrxl9FPg78Dqkv4I\nbAkc0MygzMysemXeMrpe0t3AZqSqou9ExPSmR2ZmZpUq+4tpq5KavO4HbCNpz+aFZGZmrdDhHYKk\nc4DhwH3Ae3lwAFc2MS4zM6tYmWcIm0XEuk2PxMzMWqpMldHtkpwQzMx6uTJ3CH8gJYXnSa+bCoiI\nGN7UyMzMrFJlEsI5wH7AZOY+QzAzs16mTEJ4KiKubnokZmbWUmUSwoOSLgSuofAN5YjwW0ZmZr1I\nmYSwBCkR7FQY5tdOzcx6mTLfVP5qFYGYmVlrtZsQJB0RESdKOo3csF1RRBza1MjMzKxSje4QHsj/\nJ1QRiJmZtVa7CSEirsmdb0TEZcVxkkY2NSozM6tcmW8q/7DkMDMz68EaPUPYGdgFWFXSqYVRywCz\nmx2YmZlVq9EzhGdJzw92ByYWhr8GfK+ZQZmZWfUaPUO4B7hH0oUR8W6FMZmZWQuU+WLaJySNAobk\n6dsat1uzmYGZmVm1yiSEs0lVRBOBOc0Nx8zMWqVMQnglIq5teiRmZtZSZRLCTZJOIrVdVGzc7u6m\nRWVmZpUrkxA2zf9HFIYFsEP3h2NmZq1SpnG77asIxMzMWqvDbypLGiTpbEnX5v51JR3Y/NDMzKxK\nZZquGAOMBVbJ/Q8D321WQGZm1hplEsKAiLiU/HvKETEbv35qZtbrlEkIr0takfybCJI2A15palRm\nZla5Mm8ZHQZcDQyTdCswENirqVGZmVnlyrxldLekbYF1SM1WPOS2jczMep92q4wkbSJpJXj/ucHG\nwPHAryStUFF8ZmZWkUbPEH4HvAMgaRvgBOA80vOD0c0PzczMqtSoyqhPRMzM3XsDoyPiCuAKSZOa\nH5qZmVWp0R1CH0ltCeOTwI2FcWUeRpuZWQ/S6MR+ETBe0nTgTeAWAElr4ddOzcx6nUa/mHa8pH8A\nKwPXRUTkUYsA364iODMzq07Dqp+IuKPOsIebF46ZmbVKmW8qm5nZB4ATgpmZAU4IZmaWOSGYmRng\nhGBmZpkTgpmZAU4IZmaWOSGYmRnghGBmZpkTgpmZAU4IZmaWOSGYmRnghGBmZpkTgpmZAU4IZmaW\nOSGYmRnghGBmZllLEoKkkZLuk/SepBGtiMHMzObV8Cc0m2gKsCfwu1YsfOhRf51v2BMn7NqCSMzM\n5mr1uakldwgR8UBEPNSKZddb4Y2Gm5lVYWE4N/kZgpmZAU2sMpJ0A7BSnVFHR8RVnZjPwcDBAIMH\nD+6m6MzMrFbTEkJE7NhN8xkNjAYYMWJEdMc8zcxsfq4yMjMzoHWvnX5O0tPA5sBfJY2tatntPbH3\nW0Zm1koLw7lJET2nFmbEiBExYcKEVodhZtajSJoYER1+58tVRmZmBjghmJlZ5oRgZmaAE4KZmWVO\nCGZmBjghmJlZ1qNeO5U0DXiyzqgBwPSKw6lKby4b9O7yuWw9V28r35CIGNjRRD0qIbRH0oQy79j2\nRL25bNC7y+ey9Vy9vXztcZWRmZkBTghmZpb1loQwutUBNFFvLhv07vK5bD1Xby9fXb3iGYKZmXVd\nb7lDMDOzLnJCMDMzoIclBEn/IekhSY9IOqrO+MUkXZLH3ylpaPVRLpgSZdtG0t2SZkvaqxUxLqgS\nZTtM0v2S7pX0D0lDWhHngipRvkMkTZY0SdI/Ja3bijgXREdlK0y3l6SQ1GNe1Syx3Q6QNC1vt0mS\nvtaKOCsVET3iD+gDPAqsCfQD7gHWrZnmm8CZufuLwCWtjrsbyzYUGA6cB+zV6pi7uWzbA0vm7m/0\nlO3WifItU+jeHfh7q+PurrLl6ZYGbgbuAEa0Ou5u3G4HAKe3OtYq/3rSHcIngEci4rGIeAe4GNij\nZpo9gD/k7suBT0pShTEuqA7LFhFPRMS9wHutCLALypTtpoh4I/feAaxWcYxdUaZ8rxZ6+wM95U2O\nMsccwH8DJwJvVRlcF5Ut2wdKT0oIqwJTC/1P52F1p4mI2cArwIqVRNc1ZcrWU3W2bAcC1zY1ou5V\nqnySviXpUdKJ89CKYuuqDssm6ePA6hHxlyoD6wZl98vP56rMyyWtXk1ordOTEkK9K/3aK60y0yyM\nemrcZZQum6R9gRHASU2NqHuVKl9E/CYihgFHAsc0Paru0bBskhYBTga+X1lE3afMdrsGGBoRw4Eb\nmFv70Gv1pITwNFDM0KsBz7Y3jaRFgWWBmZVE1zVlytZTlSqbpB2Bo4HdI+LtimLrDp3ddhcDn21q\nRN2no7ItDXwMGCfpCWAz4Ooe8mC5w+0WETMK++JZwMYVxdYyPSkh/AtYW9IakvqRHhpfXTPN1cD+\nuXsv4MbIT4cWcmXK1lN1WLZc7fA7UjJ4sQUxdkWZ8q1d6N0V+L8K4+uKhmWLiFciYkBEDI2IoaTn\nP7tHxITWhNspZbbbyoXe3YEHKoyvNVr9VLszf8AuwMOktwOOzsOOI+2EAIsDlwGPAHcBa7Y65m4s\n2yakq5rXgRnAfa2OuRvLdgPwAjAp/13d6pi7uXynAPflst0ErNfqmLurbDXTjqOHvGVUcrv9PG+3\ne/J2+0irY272n5uuMDMzoGdVGZmZWRM5IZiZGeCEYGZmmROCmZkBTghmZpY5ITSBpJUkXSzp0dyK\n598kfbjVcbWRdFv+P1TSlxfg80dLui9/pX+SpE0XMI4NJe1S6N+9UYua3UHSdpK26KZ5nZTXw0k1\nw9tayfy3pP+TNLa7llmznKGSprQzblzbF8Tyl8bKzlOSjslxPyzpJknrNZj+9x213ppbe/1K2Rhq\nPjtfGSWtX2iBdKakx3P3DQuyjBIxHCZp8WbMe2GzaKsD6G1yY3p/Av4QEV/MwzYEBpHeeW65iGg7\nOQ0FvgxcWPazkjYHdgM2ioi3JQ0gtRa5IDYkNVXxtxzX1TT/C3nbAbOA27phXl8HBkb9b1ZfEhH/\nBSBpe+BKSdtHxML+5aZvAVsAG0TEG5J2In37eL2ImKfxOkl9IqLDJqEj4szuDDAiJpP2HSSNAf4S\nEZd35zJqHAacQ89qvG/BtPqLEL3tD9gBuLmdcSK10zMFmAzsnYdvB4wHLiUljROAfUhfrpsMDMvT\njQHOBG7J0+2Why8OnJun/TewfR6+Xp7HJOBeYO08fFb+fwepAcBJwPdITQKfRPoW573A1+uUYU/g\nmnbKt3Eux0RgLLByHj4O+EVPrhE9AAAHCElEQVSO5WFga1ISeQqYlpe/N4XmhnNZf0v6QtBjwLak\ng/IBYExhmTsBtwN3k76UuFQe/gRwbB4+GfgIKQE+DzyTl7k1MDJvj3vqbbcG2+xqYE5b7DWfeb8c\nhWHHASfn7g3zur+XdPGwfHvrKQ8fmrf53flvi8LwKbl7CVKzGPcClwB3kr8kBvwr/+8P/DWXdUpt\n3HmaqeT9rTDsfODAtn0nl+VOYCsKX0YjNUz4cB52VmFbjgJ+0NUytrPPjaHQHDzpt5B3yd3XAKNz\n99eBUbl7f+YeF2cAi+ThOzN3X7okr6/vAe/kbX8D6SL6/Nw/BTi01eecbj1/tTqA3vZHasny5HbG\nfR64nnTiHUQ6Ia5MSggv5+7FSCesY/NnvgP8OnePAf5Oqupbm/TN5cVJjYudm6f5SJ7v4sBpwD55\neD9gidzdlhC2I11dtcV3MHBM7l4MmACsUVOGpfKB9HA+mLbNw/uSrroH5v69gXNy9zjgV7l7F+CG\n3H0AhRMn8yeEi0kn5D2AV4H1c9knkk6qA0jt8PfPnzkS+EnufgL4du7+JvD73D2KfHLK/ZOBVXP3\ncmW3WXE91vnMPOXKwz4LXJu77y2st+MK27e99bQksHjuXhuYkLuHMjchHFZY38OB2dR8aziX5axC\n/7I145cBZtYpz3eA/83dAXyhMG4c6S5vlbzOV8j7wi20nxAWqIztrOsxzJsQ9iV9w1ikk/7tefj5\nwCdJbS/9GVg0Dx9Nukv+EOlipu13OY4GfpS7n27bN4BN27Zje/tMT/5zlVG1tgIuiog5wAuSxpOa\npHiVdBX3HEBuJvm6/JnJpB+QaXNpRLwH/J+kx0gJYCvSyZ+IeFDSk8CHSVc7R0taDbgyIjpqQ2cn\nYLjm/iLbsqSD8/G2CSJilqSNSVfX2wOX5Hr/CaSD7fr8ExR9gOcK874y/59IOsjLuCYiQtJk4IVI\nVQVIui/PYzVgXeDWvMx+ucz1lrlnO8u4FRgj6dLC9EXtbbPOVm0px74s6SQyPg//A+nOpl7MQ3N3\nX+D0XPU4h7Rta20DnAoQEfdKurfONJOBX0r6BelC4JZOxN7WpMEc4Io603wCGB8RMwEkXdZOnLDg\nZSzjFtKPLK1PSrwrSfoQqeG9Q4CDSNtvQt5nliDdFb1B2pduK+xL/6wz/0eAdSSdQqrqvK7OND2W\nE0L3u4/UsF49jX6sp1gP/V6h/z3m3U61bY1Ee/ONiAsl3UlqUG2spK9FxI0NYhDpqnpsg2nIJ8dx\npFYuJ5NuwSeS2lfavJ2PtZVnDuX3u+I6qF0/i+Z5XR8RX1rQZUbEIfmh+K7AJEkbRsSMwiTd9QNL\nH6dc42j1Yv4eqa2nDUh3SO3VZTdshyYiHs7JfBfg55Kui4jjCuNflfS6pDUj4rHCRzciXT0DvJW3\nf63OrKeulLGhiHgyJ4CdSHePq5AarpsREa/nZ3znRMSP5wle+hzpl+z262D+MyQNJ1UvHUq66zp4\nQWJdGPkto+53I7CYpIPaBkjaRNK2pB10b0l9JA0kXdXd1cn5j5S0iKRhpJ//eyjPd5+8rA8Dg4GH\nJK0JPBYRp5KuaIfXzOs1UhPGbcYC35DUt21ekvoXPyBpHc3beueGwJM5joH5oTOS+jZ6O6Wd5XfW\nHcCWktbKy1yyxNtc8yxT0rCIuDMifgJMZ94mkaEbtlne9geTqmteAV6StHUevR9zT7btWRZ4Lt8Z\n7ke6+6pV3Ac+xvzbGkmrAG9ExAXAL0kn+lonAadKWiJ/ZkfSXVJHLx7cBWwraXmlpuc/38H0tcqU\nsaw7SSfrm0l3DIfn/5CeA3whvwyBpBUlDSZVd26bjxkk9S/s5+/vM3kfUERcBvyU+uuwx/IdQjfL\nVRyfA36dq1LeItWtfpe0g25OeqgXwBER8bykj3RiEQ+RTiCDgEMi4i1JZwBn5qv12cABkd4A2hvY\nV9K7pIepx9XM615gtqR7SHWxp5Bu4e/OV1LTmL/t/qWA0yQtl5f1CHBwRLyTq5pOzdUiiwK/Jt0x\ntecm4ChJk0j1vp0SEdMkHQBcJGmxPPgYGr/NdQ1wuaQ9gG8D38sHvoB/kLZN0Z+os81KhLe3pK1I\ndeOPA5+PuW8Y7U/aXkuSHph/tYN5nQFcIWkkaZ29Xmea3wLn5qqiSdRPWusDJ0l6D3iXVLVS6zRg\neWCypDmk/WaPiHizUYAR8Yyk/yGdjJ8F7ie9sFBWmTKWdQuwTUQ8IelZ0rOmW3KckyUdC9yg9AM/\n75KOo39JOpBUBdr21tyPSE2Vj87TTwWOAM7Ox0eQnlv1Gm7ttAep6BU7swUiaan8jGlRUiI9JyL+\n1Oq4rDxXGZlZdxmV7/amkO6K/tzieKyTfIdgZmaA7xDMzCxzQjAzM8AJwczMMicEMzMDnBDMzCz7\nfwEZ9g9tIBV5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23c581d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(testing_data_X['donald_comp_sentiment'], testing_data_y['classification'])\n",
    "plt.plot(testing_data_X['donald_comp_sentiment'], predictions, color='red')\n",
    "plt.xlabel(\"Composite Sentiments of Donald's Original Tweets\")\n",
    "plt.ylabel(\"Sentiment of Response Tweet\")\n",
    "plt.title(\"Predicted Sentiments of Responses to Donald's Tweets\")\n",
    "plt.yticks(np.arange(min(x) - 1, max(x) + 2, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Notes about the graph </b>\n",
    "\n",
    "As you can see, our SVM exclusively predicted results of zero, regardless of the sentiment of the presidential tweet to which they were replying. This is the encoded value for what was originally -1, or negative sentiment. While it is not ideal to have the visualization showing the encoded values rather than the original values, it is incredibly difficult to decode the values, and we were  not able to find a way to do so. So the graph must be viewed with encoded values in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "<b> Why did the SVM predict exclusively negative reply sentiments?</b>\n",
    "\n",
    "There are a couple of factors as to why our SVM could have predicted exclusively negative reply sentiments. Firstly,  our sample was very small compared to most classification datasets, so we couldn’t be as accurate with our features as we could have been with a larger dataset. \n",
    "\n",
    "Secondly, instead of choosing random presidential tweets, we selected only those from a certain day. This may have created a bias, as we did not monitor Trump’s activities for the day, and it's possible that users were responding not only to his tweets but to his offline activities, as well. \n",
    "\n",
    "Thirdly, since we classified our target values for the SVM by hand, there could be inherent bias or misunderstandings in those classifications. Many tweets involve other users in conversations, and without knowing the context of the conversation, it's difficult to detect exactly what the sentiment behind each reply was. Still other tweets contained  images that couldn't be seen in the text. We automatically classified such image tweets as neutral, but in reality the images may not have been neutral—for example, they could have been positive or negative reaction GIFs. \n",
    "\n",
    "Fourthly, our hashtag and followers features were computer manually. We did not pull the hashtags and the followers from a certain dataset that was known to encompass all anti- and pro-Trump Twitter users and hashtags, since no such datasets exist. Instead, we strove to generate this information by parsing information about the users and their tweets. It's quite possible that we missed some information regarding folloewrs or hashtags that would be crucial in the interpretation and classification of our dataset. \n",
    "\n",
    "Finally, people who bother replying to any political figure's tweet in general are more likely to have a very strong opinion on the tweet or figure in question, so our data is somewhat biased in that sense, as well. There are not likely to be many neutral tweets in reply to President Trump, but rather either very positive or very negative ones.\n",
    "\n",
    "All in all, creating this project was a learning process. As we scraped, manipulated, and computed data, we realized that the project wasn't as simple as it seemed. We found limitations with Tweepy, such as limits on the number of tweets we could get at one time, or how far back in time we could reach for tweets. We found limitations with NLTK, such as its poor performance in such polarized settings where sarcasm will frequently be involved. We found limitations with using pandas and scikit-learn in tandem, since they require the use of an encoder to work together, and that encoder makes the resulting data much more difficult to interpret.\n",
    "\n",
    "The main takeaway from this project is that there were inherent flaws with the experiment itself. The responses to President Trump were so much more overwhelmingly negative than even we expected them to be that to train an SVM with them resulted in an SVM that appears only to spit out negative values. It certainly does speak to the negative attitude that the majority of vocal Twitter users have toward President Trump. However, were we to run this experiment again, it would be helpful to do it with a more diverse and sizeable dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
