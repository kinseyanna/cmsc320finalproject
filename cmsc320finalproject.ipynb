{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC320 Final Project\n",
    "## Kinsey Smith, Sarah Bullard, Yiwen Shen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"trump_twitter_image.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Our project is surrounding the Twitter account of the United States' current president, Donald Trump (@realDonaldTrump). We focused on the sentiment of the tweets of this account versus each individual tweet's replies. Our intention was to find out the difference between the sentiment of the tweet and the sentiment of its replies, and how it would reflect our current political climate. Our hypothesis was that Donald Trump's account would have more negative replies to his positive tweets, since the current political climate does not favor Donald Trump.\n",
    "\n",
    "Sentiment analysis is a way of classifying a text as having a positive, negative, or neutral sentiment using text analysis.  However, because of the complex and sarcastic components of the English language, sentiment analysis is not a sole way of categorizing something as positive or negative. Because of this, we needed other factors to tell the sentiment of a reply. In order to do this, we created a feature vector and used that to classify the sentiment of the reply and used SVM machine learning in order to have the machine classify it for us.\n",
    "\n",
    "The features in our feature vector are as follows: \n",
    "\n",
    "Our first feature was the original sentiment analysis, because although it is not reliably conclusive on its own, it can tell us something about the mood of the sentence. \n",
    "\n",
    "The second feature we worked on focused on the user who posted the reply to the specific tweet. We checked whether or not the user was following other accounts that aligned with Donald Trump's or BLM's views, including politicians of either party.\n",
    "\n",
    "The third feature we worked on also focused on the user who posted the reply to the specific tweet. We compared the user's hashtags for the last year to known Trump-positive and BLM-positive hashtags, and noted numerically the number of hashtags that were similar for each user. \n",
    "\n",
    "This notebook will be organized into four parts: Data Extraction, Data Manipulation, Data Analysis, and Data Visualization. Each part will show how we manipulated the Twitter's API in order to get the tweets that we need and come to the conclusion that we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tweepy)\n",
      "Requirement already satisfied: six>=1.7.3 in /opt/conda/lib/python3.6/site-packages (from tweepy)\n",
      "Requirement already satisfied: requests>=2.4.3 in /opt/conda/lib/python3.6/site-packages (from tweepy)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.4.1->tweepy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy)\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: unicodecsv in /opt/conda/lib/python3.6/site-packages\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.15.0-py2.py3-none-any.whl (631kB)\n",
      "\u001b[K    100% |████████████████████████████████| 634kB 907kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk>=3.1 (from textblob)\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 561kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk>=3.1->textblob)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/18/9c/1f/276bc3f421614062468cb1c9d695e6086d0c73d67ea363c501\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk, textblob\n",
      "Successfully installed nltk-3.2.5 textblob-0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# All of the imports that we need for the project.\n",
    "\n",
    "!pip install tweepy \n",
    "!pip install unidecode\n",
    "!pip install unicodecsv\n",
    "!pip install textblob\n",
    "\n",
    "import tweepy\n",
    "from tweepy import Cursor\n",
    "import textblob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import unicodecsv\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Twitter's Data\n",
    "\n",
    "In order to access Twitter's API, we had to create applications and personally get authentication tokens. Even though anyone that has a Twitter account is allowed access to Twitter's data as long as they fill out an Application form, we cannot give out these confidential tokens on this public notebook becuase it is a privacy risk. In order to get past this hurdle, we created a function that would pull from our own files on our own machines for these tokens. In the cell below is a copy of credentials.py, without the confidential information. See below the code we used to access Twitter's API in order to get the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of credentials.py \n",
    "#This is a file that holds confidential information about a Twitter user and their authentication tokens. Please do not read further if you are not authorized.\n",
    "  \n",
    "CONSUMER_KEY = ' '\n",
    "\n",
    "CONSUMER_SECRET = ' '\n",
    "\n",
    "ACCESS_TOKEN = ' '\n",
    "\n",
    "ACCESS_SECRET = ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from credentials import *\n",
    "#A function that takes these credentials and sets up the API.\n",
    "def api_setup():\n",
    "    #application authentication allows more data retrival \n",
    "    auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    return api\n",
    "# Extracting the tweets\n",
    "extract_tweets = api_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Donald Trump Replies\n",
    "tweet_ids_donald = []\n",
    "for page in tweepy.Cursor(extract_tweets.user_timeline,screen_name=\"realDonaldTrump\").pages(20):\n",
    "    for item in page:\n",
    "        tweet_ids_donald.append(item.id_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = tweepy.Cursor(extract_tweets.search,q=\"to:realDonaldTrump\").items(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query2 = tweepy.Cursor(extract_tweets.search,q=\"to:Blklivesmatter\").items(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in query:\n",
    "    if replies_donald.get(tweet.in_reply_to_status_id_str) != None:\n",
    "        #add it to the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in query2:\n",
    "    if replies_blm.get(tweet.in_reply_to_status_id_str) != None:\n",
    "        #add it to the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the data to their individual CSVs\n",
    "\n",
    "Once we accessed the data from Twitter's API, we started querying. However, since Twitter has a rule of a maximum of 15 queries in 15 minutes, and we were querying for replies of more than 15 tweets, we had to find another way to access the data when working with it. Twitter also has a rule where you can only access tweets 2 weeks before the current date, so we set that as our time limit for both tweets and their replies to measure the current poltical climate. We added the tweets and their replies dated from <b> DATE OF TWEETS AND REPLIES </b> to individual CSVs to work with them. We slowly added them to these CSVs to circumvent the 15-queries-maximum  rule Tweets.\n",
    "\n",
    "<b> Getting Donald Trump Tweets. </b>\n",
    "\n",
    "This piece of code referenced from nicolewhite will find all trump's tweets for a year and add it to a csv called trump_tweets.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/nicolewhite/167828e51d8f2b6fad75\n",
    "users = [\"realDonaldTrump\"]\n",
    "with open('trump_tweets.csv', 'wb') as file:\n",
    "    writer = unicodecsv.writer(file, delimiter = ',', quotechar = '\"')\n",
    "    # Write header row.\n",
    "    writer.writerow([\"name\",\n",
    "                    \"username\",\n",
    "                    \"followers_count\",\n",
    "                    \"listed_count\",\n",
    "                    \"following\",\n",
    "                    \"favorites\",\n",
    "                    \"verified\",\n",
    "                    \"default_profile\",\n",
    "                    \"location\",\n",
    "                    \"time_zone\",\n",
    "                    \"statuses_count\",\n",
    "                    \"description\",\n",
    "                    \"geo_enabled\",\n",
    "                    \"contributors_enabled\",\n",
    "                    \"tweet_id\",\n",
    "                    \"tweet_time\",\n",
    "                    \"tweet_text\",\n",
    "                    \"tweet_lat\",\n",
    "                    \"tweet_long\",\n",
    "                    \"tweet_source\",\n",
    "                    \"tweet_in_reply_to_screen_name\",\n",
    "                    \"tweet_direct_reply\",\n",
    "                    \"tweet_retweet_status\",\n",
    "                    \"tweet_retweet_count\",\n",
    "                    \"tweet_favorite_count\",\n",
    "                    \"tweet_hashtags\",\n",
    "                    \"tweet_hashtags_count\",\n",
    "                    \"tweet_urls\",\n",
    "                    \"tweet_urls_count\",\n",
    "                    \"tweet_user_mentions\",\n",
    "                    \"tweet_user_mentions_count\",\n",
    "                    \"tweet_media_type\",\n",
    "                    \"tweet_contributors\"])\n",
    "\n",
    "    for user in users:\n",
    "        user_obj = api.get_user(user)\n",
    "\n",
    "        # Gather info specific to the current user.\n",
    "        user_info = [user_obj.name,\n",
    "                     user_obj.screen_name,\n",
    "                     user_obj.followers_count,\n",
    "                     user_obj.listed_count,\n",
    "                     user_obj.friends_count,\n",
    "                     user_obj.favourites_count,\n",
    "                     user_obj.verified,\n",
    "                     user_obj.default_profile,\n",
    "                     user_obj.location,\n",
    "                     user_obj.time_zone,\n",
    "                     user_obj.statuses_count,\n",
    "                     user_obj.description,\n",
    "                     user_obj.geo_enabled,\n",
    "                     user_obj.contributors_enabled]\n",
    "\n",
    "        # Get 5000 most recent tweets for the current user.\n",
    "        # api.search, q=\"to:\"+user  api.user_timeline, screen_name = user \n",
    "\n",
    "        \n",
    "        for tweet in Cursor(api.user_timeline, screen_name = user).items(5000):\n",
    "\n",
    "                    # Latitude and longitude stored as array of floats within a dictionary.\n",
    "                    lat = tweet.coordinates['coordinates'][1] if tweet.coordinates != None else None\n",
    "                    long = tweet.coordinates['coordinates'][0] if tweet.coordinates != None else None\n",
    "                    # If tweet is not in reply to a screen name, it is not a direct reply.\n",
    "                    direct_reply = True if tweet.in_reply_to_screen_name != \"\" else False\n",
    "                    # Retweets start with \"RT ...\"\n",
    "                    retweet_status = True if tweet.text[0:3] == \"RT \" else False\n",
    "\n",
    "                    # Get info specific to the current tweet of the current user.\n",
    "                    tweet_info = [tweet.id,\n",
    "                                  tweet.created_at,\n",
    "                                  unidecode(tweet.text),\n",
    "                                  lat,\n",
    "                                  long,\n",
    "                                  tweet.source,\n",
    "                                  tweet.in_reply_to_screen_name,\n",
    "                                  direct_reply,\n",
    "                                  retweet_status,\n",
    "                                  tweet.retweet_count,\n",
    "                                  tweet.favorite_count]\n",
    "\n",
    "                    # Below entities are stored as variable-length dictionaries, if present.\n",
    "                    hashtags = []\n",
    "                    hashtags_data = tweet.entities.get('hashtags', None)\n",
    "                    if(hashtags_data != None):\n",
    "                        for i in range(len(hashtags_data)):\n",
    "                            hashtags.append(unidecode(hashtags_data[i]['text']))\n",
    "\n",
    "                    urls = []\n",
    "                    urls_data = tweet.entities.get('urls', None)\n",
    "                    if(urls_data != None):\n",
    "                        for i in range(len(urls_data)):\n",
    "                            urls.append(unidecode(urls_data[i]['url']))\n",
    "\n",
    "                    user_mentions = []\n",
    "                    user_mentions_data = tweet.entities.get('user_mentions', None)\n",
    "                    if(user_mentions_data != None):\n",
    "                        for i in range(len(user_mentions_data)):\n",
    "                            user_mentions.append(unidecode(user_mentions_data[i]['screen_name']))\n",
    "\n",
    "                    media = []\n",
    "                    media_data = tweet.entities.get('media', None)\n",
    "                    if(media_data != None):\n",
    "                        for i in range(len(media_data)):\n",
    "                            media.append(unidecode(media_data[i]['type']))\n",
    "\n",
    "                    contributors = []\n",
    "                    if(tweet.contributors != None):\n",
    "                        for contributor in tweet.contributors:\n",
    "                            contributors.append(unidecode(contributor['screen_name']))\n",
    "\n",
    "                    more_tweet_info = [', '.join(hashtags),\n",
    "                                       len(hashtags),\n",
    "                                       ', '.join(urls),\n",
    "                                       len(urls),\n",
    "                                       ', '.join(user_mentions),\n",
    "                                       len(user_mentions),\n",
    "                                       ', '.join(media),\n",
    "                                       ', '.join(contributors)]\n",
    "\n",
    "                    # Write data to CSV.\n",
    "                    writer.writerow(user_info + tweet_info + more_tweet_info)\n",
    "\n",
    "        # Show progress.\n",
    "        print(\"Wrote tweets by %s to CSV.\" % user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the Data in a Functional Way\n",
    "\n",
    "Now that the data is in a csv and collected, we can put it into a dataframe to work with. \n",
    "\n",
    "We also deleted unnecessary columns in the tweet json, like followers_count and following, which don't matter in regards to what we are doing. Since the Twitter json structure doesn't include the tweet id itself and (if it is a reply) the id of the tweet it is replying to, we had to put that information as well as the text of the tweet (to match them) into a separate CSV and compare them to add both sets of information to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_retweet_status</th>\n",
       "      <th>tweet_hashtags</th>\n",
       "      <th>tweet_user_mentions</th>\n",
       "      <th>tweet_media_type</th>\n",
       "      <th>tweet_contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-09 23:47:55</td>\n",
       "      <td>Great Army - Navy Game. Army wins 14 to 13 and...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939634404267380736</td>\n",
       "      <td>2017-12-09 23:14:34</td>\n",
       "      <td>.@daveweigel of the Washington Post just admit...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daveweigel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939616077356642304</td>\n",
       "      <td>2017-12-09 22:01:44</td>\n",
       "      <td>.@DaveWeigel @WashingtonPost put out a phony p...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daveweigel, washingtonpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939564681743814661</td>\n",
       "      <td>2017-12-09 18:37:31</td>\n",
       "      <td>Have a great game today, @USArmy and @USNavy -...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USArmy, USNavy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939560154269405184</td>\n",
       "      <td>2017-12-09 18:19:31</td>\n",
       "      <td>It was my great honor to celebrate the opening...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939521466634326016</td>\n",
       "      <td>2017-12-09 15:45:47</td>\n",
       "      <td>Heading to the great state of Mississippi at t...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PhilBryantMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939485131693322240</td>\n",
       "      <td>2017-12-09 13:21:24</td>\n",
       "      <td>CNN'S slogan is CNN, THE MOST TRUSTED NAME IN ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939480342779580416</td>\n",
       "      <td>2017-12-09 13:02:23</td>\n",
       "      <td>Fake News CNN made a vicious and purposeful mi...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939477807813595136</td>\n",
       "      <td>2017-12-09 12:52:18</td>\n",
       "      <td>A big contingent of very enthusiastic Roy Moor...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939475127552618496</td>\n",
       "      <td>2017-12-09 12:41:39</td>\n",
       "      <td>GREAT EVENING last night in Pensacola, Florida...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939375570919612416</td>\n",
       "      <td>2017-12-09 06:06:03</td>\n",
       "      <td>We believe that every American should stand fo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939355447273906182</td>\n",
       "      <td>2017-12-09 04:46:05</td>\n",
       "      <td>This is your land, this is your home, and it's...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939299624875118592</td>\n",
       "      <td>2017-12-09 01:04:16</td>\n",
       "      <td>Just arrived at the Pensacola Bay Center. Join...</td>\n",
       "      <td>False</td>\n",
       "      <td>MAGA</td>\n",
       "      <td>FoxNews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>939274666404909056</td>\n",
       "      <td>2017-12-08 23:25:06</td>\n",
       "      <td>On my way to Pensacola, Florida. See everyone ...</td>\n",
       "      <td>False</td>\n",
       "      <td>MAGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>photo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username        location                   time_zone  \\\n",
       "1   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "2   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "3   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "4   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "5   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "6   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "7   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "8   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "9   realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "10  realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "11  realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "12  realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "13  realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "14  realDonaldTrump  Washington, DC  Eastern Time (US & Canada)   \n",
       "\n",
       "              tweet_id           tweet_time  \\\n",
       "1   939642796289470464  2017-12-09 23:47:55   \n",
       "2   939634404267380736  2017-12-09 23:14:34   \n",
       "3   939616077356642304  2017-12-09 22:01:44   \n",
       "4   939564681743814661  2017-12-09 18:37:31   \n",
       "5   939560154269405184  2017-12-09 18:19:31   \n",
       "6   939521466634326016  2017-12-09 15:45:47   \n",
       "7   939485131693322240  2017-12-09 13:21:24   \n",
       "8   939480342779580416  2017-12-09 13:02:23   \n",
       "9   939477807813595136  2017-12-09 12:52:18   \n",
       "10  939475127552618496  2017-12-09 12:41:39   \n",
       "11  939375570919612416  2017-12-09 06:06:03   \n",
       "12  939355447273906182  2017-12-09 04:46:05   \n",
       "13  939299624875118592  2017-12-09 01:04:16   \n",
       "14  939274666404909056  2017-12-08 23:25:06   \n",
       "\n",
       "                                           tweet_text tweet_retweet_status  \\\n",
       "1   Great Army - Navy Game. Army wins 14 to 13 and...                False   \n",
       "2   .@daveweigel of the Washington Post just admit...                False   \n",
       "3   .@DaveWeigel @WashingtonPost put out a phony p...                False   \n",
       "4   Have a great game today, @USArmy and @USNavy -...                False   \n",
       "5   It was my great honor to celebrate the opening...                False   \n",
       "6   Heading to the great state of Mississippi at t...                False   \n",
       "7   CNN'S slogan is CNN, THE MOST TRUSTED NAME IN ...                False   \n",
       "8   Fake News CNN made a vicious and purposeful mi...                False   \n",
       "9   A big contingent of very enthusiastic Roy Moor...                False   \n",
       "10  GREAT EVENING last night in Pensacola, Florida...                False   \n",
       "11  We believe that every American should stand fo...                False   \n",
       "12  This is your land, this is your home, and it's...                False   \n",
       "13  Just arrived at the Pensacola Bay Center. Join...                False   \n",
       "14  On my way to Pensacola, Florida. See everyone ...                False   \n",
       "\n",
       "   tweet_hashtags         tweet_user_mentions tweet_media_type  \\\n",
       "1             NaN                         NaN              NaN   \n",
       "2             NaN                  daveweigel              NaN   \n",
       "3             NaN  daveweigel, washingtonpost              NaN   \n",
       "4             NaN              USArmy, USNavy              NaN   \n",
       "5             NaN                         NaN              NaN   \n",
       "6             NaN                PhilBryantMS              NaN   \n",
       "7             NaN                         NaN              NaN   \n",
       "8             NaN                         NaN              NaN   \n",
       "9             NaN                         NaN              NaN   \n",
       "10            NaN                         NaN              NaN   \n",
       "11            NaN                         NaN              NaN   \n",
       "12            NaN                         NaN              NaN   \n",
       "13           MAGA                     FoxNews              NaN   \n",
       "14           MAGA                         NaN            photo   \n",
       "\n",
       "    tweet_contributors  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "5                  NaN  \n",
       "6                  NaN  \n",
       "7                  NaN  \n",
       "8                  NaN  \n",
       "9                  NaN  \n",
       "10                 NaN  \n",
       "11                 NaN  \n",
       "12                 NaN  \n",
       "13                 NaN  \n",
       "14                 NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Donald Tweets\n",
    "data_donald = pd.read_csv(\"trump_tweets.csv\")\n",
    "del data_donald[\"name\"]\n",
    "del data_donald[\"followers_count\"]\n",
    "del data_donald[\"listed_count\"]\n",
    "del data_donald[\"following\"]\n",
    "del data_donald[\"favorites\"]\n",
    "del data_donald[\"verified\"]\n",
    "del data_donald[\"default_profile\"]\n",
    "del data_donald[\"statuses_count\"]\n",
    "del data_donald[\"description\"]\n",
    "del data_donald[\"geo_enabled\"]\n",
    "del data_donald[\"contributors_enabled\"]\n",
    "del data_donald[\"tweet_lat\"]\n",
    "del data_donald[\"tweet_long\"]\n",
    "del data_donald[\"tweet_source\"]\n",
    "del data_donald[\"tweet_in_reply_to_screen_name\"]\n",
    "del data_donald[\"tweet_direct_reply\"]\n",
    "del data_donald[\"tweet_retweet_count\"]\n",
    "del data_donald[\"tweet_favorite_count\"]\n",
    "del data_donald[\"tweet_hashtags_count\"]\n",
    "del data_donald[\"tweet_urls\"]\n",
    "del data_donald[\"tweet_urls_count\"]\n",
    "del data_donald[\"tweet_user_mentions_count\"]\n",
    "data_donald=data_donald[1:15]\n",
    "data_donald"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Getting replies to Donald Trump Tweets. </b>\n",
    "\n",
    "The following code will collect replies to trump's tweet to a csv file. Due to twitter's rate limit on search api we only collect 20 replies. With the reply_id we will be able to see which Trump's tweet above the user is replying to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id_list = data_donald['tweet_id'].tolist()\n",
    "\n",
    "with open('trump_replies.csv', 'wb') as file:\n",
    "    writer = unicodecsv.writer(file, delimiter = ',', quotechar = '\"')\n",
    "    writer.writerow([\n",
    "                    \"username\",\n",
    "                    \"id\",\n",
    "                    \"reply_id\",\n",
    "                    \"date\",\n",
    "                    \"tweet\"\n",
    "                    ])\n",
    "                     \n",
    "\n",
    "    for otweet_id in tweet_id_list:\n",
    "        \n",
    "        i=0\n",
    "        print(otweet_id)\n",
    "        for tweet in tweepy.Cursor(extractor.search, q=\"to:realDonaldTrump\", since_id= otweet_id).items():\n",
    "                \n",
    "                \n",
    "                if str(tweet.in_reply_to_status_id) == str(otweet_id):\n",
    "                    i=i+1\n",
    "                    print(i)\n",
    "                    if(i==20):\n",
    "                        break\n",
    "\n",
    "                    info = [tweet.user.screen_name,\n",
    "                             tweet.id,\n",
    "                             tweet.in_reply_to_status_id,\n",
    "                             tweet.created_at,\n",
    "                             unidecode(tweet.text),\n",
    "                            ]\n",
    "\n",
    "\n",
    "                    writer.writerow(info)\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the resulting csv. As we notice due to the constraint of the search api, the replies we got are all very recent as in 12-11 compared with the 12-9 in the original tweets. This is due to the search api searching from most recent and we have no comntrol of. This may affect the result as the recent tweets may be affected by recent events. This can be solbved by uisng a better search engine that dosen't have rate limit and can sample search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...  \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ  \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia  \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s  \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replies of Trump\n",
    "data_donald_replies = pd.read_csv(\"trump_replies.csv\")\n",
    "\n",
    "data_donald_replies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Feature vectors </b>\n",
    "\n",
    "The follwing code will find what the users from data_donald_replies are following and will put that into feature vectors in a cloumn called score. Start at 0, if they’re following people to the right wing hanldes +1, if they are following people to the left -1. Again,due to api's rate limit this took very long time and we have to store the result in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_wing_handles_string = \",@AnnCoulter,@StefanMolyneux,@MarkSteynOnline,@ezralevant,@nntaleb,@Lauren_Southern,@RealJamesWoods,@IngrahamAngle,@benshapiro,@charliekirk11,@jihadwatchRS,@scrowder,@RubinReport,@Nigel_Farage,@michellemalkin,@PrisonPlanet,@ScottAdamsSays,@andrewklavan,@Gavin_McInnes,@Cernovich,@TuckerCarlson,@mitchellvii,@NolteNC,@JamesOKeefeIII,@DLoesch,@JackPosobiec,@BuckSexton,@KatiePavlich,@marklevinshow,@seanhannity,@guypbenson,@JimDeMint,@BrentBozell,@larryelder,@BillOReilly,@limbaugh\"\n",
    "right_wing_handles = right_wing_handles_string.split(\",@\")   \n",
    "left_wing_handles_string = \",@People4Bernie,@BuzzfeedBen,@jonlovett,@ChrisMurphyCT,@HeerJeet,@deray,@chrislhayes,@ezraklein,@jbouie,@cjane87,@julietlapidos,@meaganmday,@emmaogreen,@ObsoleteDogma,@billmaher,@BillNye,@iamjohnoliver,@kmcnuggets,@StephenAtHome,@donnabrazile,@PPact,@iraglass,@chelseahandler,@kamalaharris,@elizabethwarren,@sensherrodbrown\"\n",
    "left_wing_handles = left_wing_handles_string.split(\",@\")  \n",
    "\n",
    "right_wing_handles.pop(0)\n",
    "left_wing_handles.pop(0)\n",
    "\n",
    "#getting user's following list\n",
    "fl_dict = {}\n",
    "for u_name in username_list:\n",
    "    fl =[]\n",
    "    users = tweepy.Cursor(extractor.friends, screen_name=u_name, count = 200).items()\n",
    "    for u in users:\n",
    "        fl.append(u.screen_name)\n",
    "     \n",
    "    fl_dict[u_name] = fl\n",
    "    \n",
    "#for each user, find how many they are following that are in right wing handles and that for left wing as well\n",
    "#the score will be right minus left\n",
    "score_list=[]\n",
    "for user in fl_dict:\n",
    "        user_set = set(fl_dict[user])\n",
    "        score= len(list(user_set & right_wing_set)) - len(list( user_set & left_wing_set))\n",
    "\n",
    "\n",
    "#the data is then saved to csv called\n",
    "data_donald_replies['following_feature_vector'] = score_list\n",
    "data_donald_replies.to_csv(\"trump_replies_with_following_feature.csv\", sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>following_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoltanCaptain</td>\n",
       "      <td>940075314398486528</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:26:35</td>\n",
       "      <td>@realDonaldTrump Resign before you are impeach...</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nodictatorinusa</td>\n",
       "      <td>940073512282218496</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:19:25</td>\n",
       "      <td>@realDonaldTrump  https://t.co/tuQNvmQYEZ</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MikeMerica</td>\n",
       "      <td>940073344891699200</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:18:45</td>\n",
       "      <td>@realDonaldTrump Now go play roulette in Russia</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rondavt74</td>\n",
       "      <td>940072314086887424</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:14:40</td>\n",
       "      <td>@realDonaldTrump  https://t.co/sIPqjPoX3s</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMHansen0528</td>\n",
       "      <td>940071620823040001</td>\n",
       "      <td>939642796289470464</td>\n",
       "      <td>2017-12-11 04:11:54</td>\n",
       "      <td>@realDonaldTrump You know nothing about football!</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                  id            reply_id  \\\n",
       "0    ZoltanCaptain  940075314398486528  939642796289470464   \n",
       "1  nodictatorinusa  940073512282218496  939642796289470464   \n",
       "2      1MikeMerica  940073344891699200  939642796289470464   \n",
       "3        rondavt74  940072314086887424  939642796289470464   \n",
       "4     TMHansen0528  940071620823040001  939642796289470464   \n",
       "\n",
       "                  date                                              tweet  \\\n",
       "0  2017-12-11 04:26:35  @realDonaldTrump Resign before you are impeach...   \n",
       "1  2017-12-11 04:19:25          @realDonaldTrump  https://t.co/tuQNvmQYEZ   \n",
       "2  2017-12-11 04:18:45    @realDonaldTrump Now go play roulette in Russia   \n",
       "3  2017-12-11 04:14:40          @realDonaldTrump  https://t.co/sIPqjPoX3s   \n",
       "4  2017-12-11 04:11:54  @realDonaldTrump You know nothing about football!   \n",
       "\n",
       "   following_feature_vector  \n",
       "0                        -8  \n",
       "1                        -7  \n",
       "2                        -1  \n",
       "3                        -3  \n",
       "4                        -3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_donald_replies_with_following_feature = pd.read_csv(\"trump_replies_with_following_feature.csv\")\n",
    "data_donald_replies_with_following_feature.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis\n",
    "\n",
    "As explained before, sentiment analysis is a basic way of analyzing a text to tell if it is of positive, negative, or neutral sentiment. NLTK is the library we will use to do this section. This will be one of the features for the feature vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 784 words at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the sentiment analysis for each type of tweet\n",
    "sentiment_nltk_donald = []\n",
    "for _,x in data_donald.iterrows():\n",
    "    sentiment_nltk_donald.append((x[\"tweet_text\"],sia.polarity_scores(x['tweet_text'])))\n",
    "sentiment_nltk_donald_replies = []\n",
    "for _,x in data_donald_replies.iterrows():\n",
    "    sentiment_nltk_donald_replies.append((x[\"tweet_text\"],sia.polarity_scores(x['tweet_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@realDonaldTrump @WhiteHouse  https://t.co/Po44ehzuU4', {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0})\n",
      "('@realDonaldTrump @POTUS Moron!', {'neg': 0.636, 'neu': 0.364, 'pos': 0.0, 'compound': -0.5411})\n",
      "(\"@realDonaldTrump I'm not convinced that the majority of Americans believe that. Heck, he helped you win by what he... https://t.co/OhZPoFZoLC\", {'neg': 0.094, 'neu': 0.748, 'pos': 0.158, 'compound': 0.3699})\n",
      "('@realDonaldTrump Awesome job!  Keep it up!', {'neg': 0.0, 'neu': 0.516, 'pos': 0.484, 'compound': 0.6892})\n",
      "('@realDonaldTrump No you did not you moron', {'neg': 0.224, 'neu': 0.509, 'pos': 0.267, 'compound': 0.1098})\n",
      "('@realDonaldTrump Coherent, grammatical, appropriate capitalization ... obviously ghostwritten.', {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0})\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 6:\n",
    "    print(sentiment_nltk_donald_replies[i])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 nonredundant lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
